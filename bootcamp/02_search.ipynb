{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using a colab notebook:\n",
    "#!pip install aleph-alpha-client langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Client, SemanticEmbeddingRequest, SemanticEmbeddingResponse, SemanticRepresentation, Prompt, TextControl\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.llms import AlephAlpha\n",
    "from langchain.embeddings import AlephAlphaSymmetricSemanticEmbedding, AlephAlphaAsymmetricSemanticEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = Client(token=os.getenv(\"AA_TOKEN\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Use the API to create an embedding of a text\n",
    "Use the \"Semantic Search\" API to create an embedding of a text. The API returns a JSON object with the embedding of the text.\n",
    "You can read more about the semantic search API here: https://docs.aleph-alpha.com/docs/tasks/semantic_embed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Use the API to find out how similar these three texts are\n",
    "Use scipys cosine_similarity 'spatial.distance.cosine' to find out how similar these three texts are. The function returns a number between 0 and 1, where 0 means the texts are completely different and 1 means the texts are identical.\n",
    "Remember that cosine_similarity returns a distance, not a similarity. So you need to subtract the distance from 1 to get the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"The sun is shining\", \n",
    "         \"It's pretty sunny today\", \n",
    "         \"Her smile shines brightly down upon the south african people\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create an embedding request (Symmetric), get the response, and extract the embedding\n",
    "text_embeddings = []\n",
    "for text in texts:\n",
    "    embedding_request = None # TODO\n",
    "    embedding_response = None # TODO\n",
    "    embedding = embedding_response.embedding\n",
    "    text_embeddings.append(embedding)\n",
    "\n",
    "# TODO: Calculate the cosine similarity between the embeddings\n",
    "similarity_1_2 = 1 - spatial.distance.cosine(text_embeddings[0], text_embeddings[1])\n",
    "similarity_1_3 = 1 - spatial.distance.cosine(text_embeddings[0], text_embeddings[2])\n",
    "similarity_2_3 = 1 - spatial.distance.cosine(text_embeddings[1], text_embeddings[2])\n",
    "\n",
    "print(f\"Similarity between {texts[0][:10]} and {texts[1][:10]}\", similarity_1_2)\n",
    "print(f\"Similarity between text {texts[0][:10]} and {texts[2][:10]}: \", similarity_1_3)\n",
    "print(f\"Similarity between text {texts[1][:10]} and {texts[2][:10]}: \", similarity_2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic similarity with langchain    \n",
    "embeddings = AlephAlphaSymmetricSemanticEmbedding()\n",
    "\n",
    "text_embeddings = embeddings.embed_documents(texts)\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i+1, len(texts)):\n",
    "        similarity = 1 - spatial.distance.cosine(text_embeddings[i], text_embeddings[j])\n",
    "        print(f\"Similarity between {texts[i][:10]} and {texts[j][:10]}\", similarity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Use the API on an asymmetric embedding case to find the answer to the question\n",
    "Asymmetric embeddings are useful when you want to find the answer to a question. For example, if you want to find the answer to the question \"What is the capital of France?\", you can use the API to create an embedding of the question and an embedding of the answer. Then you can use the cosine_similarity function to find out how similar the question and the answer are. The answer is the one with the highest similarity.\n",
    "\n",
    "We will try this on parts of the manual.\n",
    "\n",
    "You can find the documentation on the asymmetric embedding here: https://docs.aleph-alpha.com/docs/tasks/semantic_embed/#code-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data in the data.md file\n",
    "with open(\"data.md\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# Split the data into a list of texts\n",
    "texts = data.split(\"#####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"What countries have social elements in their guidelines?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create embeddings (Document) for the contexts and the question (Query)\n",
    "embedded_contexts = []\n",
    "for context in texts:\n",
    "    # TODO: create an embedding request (Document), \n",
    "    # get the response, \n",
    "    # and extract the embedding\n",
    "    pass # TODO\n",
    "\n",
    "# create an embedding request (Query), \n",
    "# get the response, \n",
    "# and extract the embedding\n",
    "embedded_question = client.semantic_embed(\n",
    "    SemanticEmbeddingRequest(\n",
    "        prompt=Prompt.from_text(question), \n",
    "        representation=SemanticRepresentation.Query, \n",
    "        compress_to_size=128), \n",
    "    model=\"luminous-base\").embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings (Document) for the contexts and the question (Query) with langchain\n",
    "\n",
    "# Load the embedding model\n",
    "embeddings = AlephAlphaAsymmetricSemanticEmbedding()\n",
    "\n",
    "# create embeddings (Document) for the contexts and the question (Query)\n",
    "embedded_contexts = embeddings.embed_documents(texts)\n",
    "embedded_question = embeddings.embed_query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between the embeddings\n",
    "similarities = []\n",
    "for embedded_context in embedded_contexts:\n",
    "    # TODO: Calculate the cosine similarity between the embeddings\n",
    "    similarity = 1 - spatial.distance.cosine(embedded_context, embedded_question)\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "print(\"Similarities: \", similarities)\n",
    "print(\"\\n\\nSelected Context: \\n\" + texts[np.argmax(similarities)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpe-hmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fb2148b4dec95289a29917982720107fca12734259108fc6abb6a274b2eb7e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
