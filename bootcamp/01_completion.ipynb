{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Client, Prompt, CompletionRequest, CompletionResponse\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.llms import AlephAlpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# for using the Aleph Alpha API\n",
    "client = Client(token=os.getenv(\"AA_TOKEN\"))\n",
    "\n",
    "# for using LangChain\n",
    "aleph_alpha = AlephAlpha(aleph_alpha_api_key=os.getenv(\"AA_TOKEN\"), model=\"luminous-extended\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Use the completion function of the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the full-fledged AA API for a simple completion\n",
    "\n",
    "# Define the prompt\n",
    "prompt = Prompt.from_text(\"An apple a day\")\n",
    "\n",
    "# TODO Create a completion request with parameters\n",
    "request = CompletionRequest() # https://docs.aleph-alpha.com/docs/tasks/complete/\n",
    "\n",
    "# TODO Send the request to the API\n",
    "response = None # https://docs.aleph-alpha.com/docs/tasks/complete/\n",
    "\n",
    "# Get the completion\n",
    "completion = response.completions[0].completion\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LangChain for a simple completion\n",
    "\n",
    "# define the prompt\n",
    "prompt = \"An apple a day\"\n",
    "\n",
    "# define the parameters\n",
    "params = {} # https://python.langchain.com/en/latest/modules/models/llms/integrations/aleph_alpha.html\n",
    "\n",
    "# TODO define the model\n",
    "aleph_alpha = None # https://python.langchain.com/en/latest/modules/models/llms/integrations/aleph_alpha.html\n",
    "\n",
    "# TODO get the completion\n",
    "response = None # https://python.langchain.com/en/latest/modules/models/llms/integrations/aleph_alpha.html\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Write a few shot prompt that generates keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Pinocchio was not a boy, but a wooden puppet. He was made by a carpenter named Geppetto. He was a very naughty puppet. He was always getting into trouble. He was always lying.\",\n",
    "    \"Most commonly associated with the polar regions, permafrost is soil and rocky material that stays frozen continuously for at least two years. Normally it lies beneath an active layer that melts and freezes depending on the season. Less well known is that permafrost can also be found on steep mountain walls.\",\n",
    "    \"Toheroa are a clam that grow as large as a human hand and burrow in intertidal sands on just a handful of epic surf-swept beaches – mainly on the west coast of New Zealand's North Island, but also in isolated colonies at places like Oreti, a beach at the nation's southern tip.\",\n",
    "    \"On the neighbourhood's southern edge, cutting through Queens like a backbone, is Roosevelt Avenue. Here, conversations don't stop when the 7 train rattles overhead, they just get louder. Phone repair shops run by Tibetans with makeshift shrines displayed between plastic iPhone covers abut Latin American bakeries churning out pillowy almojábanas (Colombian cheese bread) and crispy empanadas.\"\n",
    "]\n",
    "\n",
    "# TODO write a function that takes a text and returns a list of keywords\n",
    "\n",
    "def get_keywords(text):\n",
    "    # TODO Write a prompt that generates keywords for any text\n",
    "    # Tipp: Use few-shot learning\n",
    "    \n",
    "    # 1. TODO define the prompt\n",
    "    prompt = Prompt.from_text(f\"\"\"A prompt\"\"\")   \n",
    "    \n",
    "    # 2. TODO define the completion request \n",
    "    request = CompletionRequest()\n",
    "    \n",
    "    # 3. TODO send the request to the API\n",
    "    response = None\n",
    "    \n",
    "    # 4. get the completion\n",
    "    completion = response.completions[0].completion\n",
    "    return completion\n",
    "\n",
    "def get_keywords_langchain(text):\n",
    "    # TODO Write a prompt that generates keywords for any text\n",
    "    # Tipp: Use few-shot learning\n",
    "    \n",
    "    # 1. define the prompt\n",
    "    prompt = f\"\"\"Prompt\"\"\"\n",
    "    \n",
    "    # 2. define the parameters\n",
    "    params = {\n",
    "        \"temperature\": 0.5,\n",
    "        \"model\": \"luminous-base\",\n",
    "        \"maximum_tokens\": 100\n",
    "    }\n",
    "\n",
    "    # 3. define the model\n",
    "    aleph_alpha = AlephAlpha(aleph_alpha_api_key=os.getenv(\"AA_TOKEN\"), **params)\n",
    "    \n",
    "    # 4. get the completion\n",
    "    response = aleph_alpha(prompt=prompt, stop=[\"\\n\"])\n",
    "    return response\n",
    "    \n",
    "\n",
    "for text in texts:\n",
    "    keywords = get_keywords(text)\n",
    "    print(keywords)\n",
    "    keywords_lang = get_keywords_langchain(text)\n",
    "    print(keywords_lang)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use Langchain to run a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a chain from langchain to generate a text\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Q: {question}\n",
    "\n",
    "A:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm = AlephAlpha(model=\"luminous-extended\", maximum_tokens=20, stop_sequences=[\"Q:\"], aleph_alpha_api_key=os.getenv(\"AA_TOKEN\"))\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What is AI?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write two prompts one, that generates a question about a text and one that then answers the questions\n",
    "\n",
    "def generate_questions_and_answers(text):\n",
    "    # TODO Write a prompt that generates questions and answers for any text\n",
    "    # Tipp: Use few-shot learning\n",
    "    \n",
    "    # 1. TODO define the prompt\n",
    "    questions_prompt = Prompt.from_text(f\"\"\"A prompt\"\"\")\n",
    "    \n",
    "    # 2. TODO define the completion request for the questions\n",
    "    request = CompletionRequest()\n",
    "    response = None\n",
    "    question = response.completions[0].completion\n",
    "    \n",
    "    # 3. get the completion for answers\n",
    "    answers_prompt = Prompt.from_text(f\"\"\"A prompt\"\"\") \n",
    "    request = CompletionRequest()\n",
    "    response = None\n",
    "    \n",
    "    # 4. get the completion\n",
    "    completion = response.completions[0].completion\n",
    "    \n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write a function where the user chats with an AI, store the conversation in a list as a memory\n",
    "history = []\n",
    "def chat_with_ai(message):\n",
    "    # TODO Write a prompt that generates questions and answers for any text\n",
    "    # Tipp: Use few-shot learning\n",
    "    history.append(f\"User:{message}\")\n",
    "    \n",
    "    # 1. TODO define the prompt with the message and the history\n",
    "    prompt = Prompt.from_text(f\"\"\"A prompt\"\"\")\n",
    "    \n",
    "    # 2. TODO define the completion request for the questions\n",
    "    request = CompletionRequest()\n",
    "    response = None\n",
    "    answer = response.completions[0].completion\n",
    "\n",
    "    history.append(f\"AI:{answer}\")\n",
    "    \n",
    "    return completion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
