{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using a colab notebook:\n",
    "#!pip install aleph-alpha-client langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Client, SemanticEmbeddingRequest, SemanticEmbeddingResponse, SemanticRepresentation, Prompt, TextControl\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.llms import AlephAlpha\n",
    "from langchain.embeddings import AlephAlphaSymmetricSemanticEmbedding, AlephAlphaAsymmetricSemanticEmbedding\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = Client(token=os.getenv(\"AA_TOKEN\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use luminous embeddings as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define two classes that we want to classify\n",
    "class_1 = [\"Find balance in the digital age with mindful technology use and prioritizing self-care.\",\n",
    "\"Take charge of your digital wellbeing by setting boundaries and practicing digital detoxes.\",\n",
    "\"Promote digital wellbeing through healthy screen time habits and fostering positive online relationships.\",\n",
    "\"Explore digital wellbeing apps and tools that help you manage your digital presence and mental health.\",\n",
    "\"Prioritize your physical and mental health by practicing digital mindfulness and limiting screen time.\",\n",
    "\"Digital wellbeing starts with conscious choices, such as disconnecting from devices and engaging in offline activities.\",\n",
    "]\n",
    "\n",
    "class_2 = [\n",
    "    \"Digital natives effortlessly navigate the digital landscape, growing up in a world saturated with technology.\",\n",
    "\"Born in the digital era, digital natives possess innate digital literacy and adapt quickly to new technologies.\",\n",
    "\"Digital natives seamlessly integrate technology into their daily lives, leveraging it for communication, learning, and entertainment.\",\n",
    "\"As digital natives, they are the vanguards of technological advancements, shaping the digital landscape with their digital-first mindset.\",\n",
    "\"Digital natives are fluent in the language of emojis, hashtags, and memes, using them to express themselves in the digital realm.\",\n",
    "\"Growing up surrounded by screens, digital natives are at ease multitasking across multiple devices and platforms.\",\n",
    "]\n",
    "\n",
    "class_3 = [\n",
    "    \"Digital companies leverage innovative technologies to disrupt traditional industries and drive digital transformation.\",\n",
    "\"Agile and data-driven, digital companies thrive in the ever-evolving digital ecosystem, constantly adapting to market demands.\",\n",
    "\"Digital companies prioritize user experience, leveraging intuitive interfaces and seamless interactions to engage and retain customers.\",\n",
    "\"From e-commerce giants to fintech startups, digital companies revolutionize the way business is conducted in the digital age.\",\n",
    "\"Digital companies harness the power of big data and analytics to gain actionable insights and drive informed decision-making.\",\n",
    "\"In a borderless digital world, digital companies operate globally, transcending geographical limitations and connecting people worldwide.\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we generate embeddings for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the AlephAlpha client to embed the sentences in the two classes\n",
    "embeddings_class_1 = # TODO create embeddings for class 1\n",
    "embeddings_class_2 = # TODO create embeddings for class 2\n",
    "embeddings_class_3 = # TODO create embeddings for class 3\n",
    "\n",
    "\n",
    "new_sentence = \"In order to retain control over you life, you should try to limit your screen time and practice digital mindfulness.\"\n",
    "sentence_embedding = # TODO create embedding for new sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity to class 1:  0.6786340545121642\n",
      "Similarity to class 2:  0.24306221932952257\n",
      "Similarity to class 3:  0.1948526479923108\n"
     ]
    }
   ],
   "source": [
    "# TODO: get the average similarity of the new sentence to the two classes\n",
    "\n",
    "similarities_class_1 = # TODO get the similarities of the new sentence to the embeddings of class 1\n",
    "similarities_class_2 = # TODO get the similarities of the new sentence to the embeddings of class 2\n",
    "similarities_class_3 = # TODO get the similarities of the new sentence to the embeddings of class 3\n",
    "\n",
    "# TODO get the average similarity of the new sentence to the two classes\n",
    "avg_similarity_class_1 = np.mean(similarities_class_1)\n",
    "avg_similarity_class_2 = np.mean(similarities_class_2)\n",
    "avg_similarity_class_3 = np.mean(similarities_class_3)\n",
    "\n",
    "print(\"Similarity to class 1: \", avg_similarity_class_1)\n",
    "print(\"Similarity to class 2: \", avg_similarity_class_2)\n",
    "print(\"Similarity to class 3: \", avg_similarity_class_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's actually train a classifier on these embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class:  [0]\n"
     ]
    }
   ],
   "source": [
    "# Let's use PCA to reduce the dimensionality of the embeddings to 2D\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(embeddings_class_1 + embeddings_class_2 + embeddings_class_3)\n",
    "pca_embeddings_class_1 = pca.transform(embeddings_class_1)\n",
    "pca_embeddings_class_2 = pca.transform(embeddings_class_2)\n",
    "pca_embeddings_class_3 = pca.transform(embeddings_class_3)\n",
    "\n",
    "# Now let's plot the embeddings from all three classes\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, embeddings in enumerate([pca_embeddings_class_1, pca_embeddings_class_2, pca_embeddings_class_3]):\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=embeddings[:,0],\n",
    "        y=embeddings[:,1],\n",
    "        mode=\"markers\",\n",
    "        name=f\"Class {i+1}\",\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            color=[\"red\", \"green\", \"blue\"][i],\n",
    "        ),\n",
    "        text=class_1 + class_2 + class_3,\n",
    "        hovertemplate=\n",
    "        \"<b>%{text}</b><br><br>\" +\n",
    "\n",
    "        \"<i>Similarity to new sentence:</i><br>\" +\n",
    "        \"%{marker.color:.2f}<br>\" +\n",
    "        \"<extra></extra>\"\n",
    "    ))\n",
    "\n",
    "    \n",
    "\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classifier\n",
    "clf = # TODO create a Nearest Neighbors classifier with 3 neighbors (link to documentation: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "# use the embeddings and the class labels to train a classifier\n",
    "X = # TODO create a list of embeddings\n",
    "y = # TODO create a list of class labels\n",
    "\n",
    "# fit the classifier\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"Predicted class: \", clf.predict([sentence_embedding]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different classifier\n",
    "svm = # TODO create a Support Vector Machine classifier (link to documentation: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "svm.fit(X, y)\n",
    "\n",
    "print(\"Predicted class: \", svm.predict([sentence_embedding]))\n",
    "\n",
    "# get the probabilities for each class\n",
    "print(\"Probabilities: \", svm.predict_proba([sentence_embedding]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the embeddings of class 1\n",
    "\n",
    "aggregation_class_1 = np.mean(embeddings_class_1, axis=0)\n",
    "aggregation_class_2 = np.mean(embeddings_class_2, axis=0)\n",
    "aggregation_class_3 = np.mean(embeddings_class_3, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with three components\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# fit the PCA to the embeddings\n",
    "pca.fit(X)\n",
    "\n",
    "# transform the embeddings\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "pca_agg_class_1 = pca.transform([aggregation_class_1])\n",
    "pca_agg_class_2 = pca.transform([aggregation_class_2])\n",
    "pca_agg_class_3 = pca.transform([aggregation_class_3])\n",
    "\n",
    "\n",
    "# transform the new sentence\n",
    "\n",
    "sentence_embedding_pca = pca.transform([sentence_embedding])\n",
    "\n",
    "# plot the embeddings\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, embeddings in enumerate([pca_agg_class_1, pca_agg_class_2, pca_agg_class_3, sentence_embedding_pca]):\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=embeddings[:,0],\n",
    "        y=embeddings[:,1],\n",
    "        z=embeddings[:,2],\n",
    "        mode=\"markers\",\n",
    "        name=f\"Class {i+1}\",\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            color=[\"red\", \"green\", \"blue\", \"yellow\"][i],\n",
    "        ),\n",
    "        text=class_1 + class_2 + class_3,\n",
    "        hovertemplate=\n",
    "        \"<b>%{text}</b><br><br>\" +\n",
    "\n",
    "        \"<i>Similarity to new sentence:</i><br>\" +\n",
    "        \"%{marker.color:.2f}<br>\" +\n",
    "        \"<extra></extra>\"\n",
    "    ))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
