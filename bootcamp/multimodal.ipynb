{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Client, Prompt, Image, ImagePrompt, CompletionRequest, CompletionResponse, SemanticEmbeddingRequest, SemanticEmbeddingResponse, SemanticRepresentation\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import IPython.display as dsp\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = Client(token=os.getenv(\"AA_TOKEN\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, we will explore the multimodal capabilities\n",
    "Read up on the basic concepts of multimodal luminous here : https://docs.aleph-alpha.com/docs/multimodality/basic-principles/\n",
    "\n",
    "Also find more information on how o use the multimodal luminous API here : https://docs.aleph-alpha.com/docs/multimodality/basic-principles/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: load an image as a prompt item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"sample_image.jpg\"\n",
    "\n",
    "# loading the image from a url\n",
    "image_prompt = Image.from_url(\"https://upload.wikimedia.org/wikipedia/commons/a/a8/The_Cake_is_a_Lie_%2812521108583%29.jpg\")\n",
    "\n",
    "# display the image from the url\n",
    "dsp.Image(url=\"https://upload.wikimedia.org/wikipedia/commons/a/a8/The_Cake_is_a_Lie_%2812521108583%29.jpg\", width=300)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Use the multimodal luminous API to generate a multimodal response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write a prompt that answers a question about the image\n",
    "\n",
    "image_prompt = Image.from_url(\"https://upload.wikimedia.org/wikipedia/commons/a/a8/The_Cake_is_a_Lie_%2812521108583%29.jpg\")\n",
    "text = \"Q: What does the Graffiti say? A:\"\n",
    "\n",
    "prompt = Prompt(items=[\"TODO\"])\n",
    "request = CompletionRequest(\"TODO\")\n",
    "\n",
    "response = client.complete(request=request, model=\"luminous-extended\").completions[0].completion\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Let's use true multimodal input, with text and images as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.from_url(\"https://upload.wikimedia.org/wikipedia/commons/a/a8/The_Cake_is_a_Lie_%2812521108583%29.jpg\")\n",
    "additional_text = \"When walking down the street I was really hungry when I saw this Image.\"\n",
    "question = \"Q: What did I really want to eat afterwards? A:\"\n",
    "\n",
    "prompt = Prompt(items=[image_prompt, additional_text, question])\n",
    "request = CompletionRequest(prompt=prompt, maximum_tokens=32, stop_sequences=[\"Q:\"])\n",
    "\n",
    "response = client.complete(request=request, model=\"luminous-extended\").completions[0].completion\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpe-hmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fb2148b4dec95289a29917982720107fca12734259108fc6abb6a274b2eb7e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
