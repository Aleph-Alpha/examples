{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: The python Client\n",
    "\n",
    "In this notebook we will take a look at the basics of the python client.\n",
    "\n",
    "We will use the client to query the API and make a simple completion call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the packages\n",
    "First we import the AlephAlphaClient with the classes for models and prompts.\n",
    "This is necessary to make the API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import AlephAlphaModel, AlephAlphaClient, CompletionRequest, Prompt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the API and defining the model\n",
    "With the *AlephAlphaModel* we define which model we want to use.\n",
    "\n",
    "With the *AlephAlphaClient* we authenticate with the API and connect to the API.\n",
    "\n",
    "The token can be retrieved or just passed as a string.\n",
    "\n",
    "The available models are:\n",
    "- luminous-base\n",
    "- luminous-extended\n",
    "- luminous-supreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model and provide token for authentification\n",
    "model = AlephAlphaModel(\n",
    "    AlephAlphaClient(host=\"https://api.aleph-alpha.com\", token=os.getenv(\"API_TOKEN\")),\n",
    "    model_name = \"luminous-extended\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a prompt and Task\n",
    "With the *Prompt* module we define a prompt that is to be processed by luminous.\n",
    "\n",
    "Prompts can contain text and images, but for now we will only use text.\n",
    "\n",
    "We also define a *CompletionRequest* which we use to define the Model behaviour.\n",
    "\n",
    "With *model.complete* we send the prompt to the API and get a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the prompt\n",
    "prompt = Prompt(\"Q: What is AI? A:\")\n",
    "\n",
    "# create a CompletionRequest\n",
    "request = CompletionRequest(prompt=prompt, maximum_tokens=20, stop_sequences=[\"Q:\"])\n",
    "\n",
    "# call the model to get the result\n",
    "result = model.complete(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the result\n",
    "\n",
    "The result is a *CompletionResponse* which contains the completion and the metadata.\n",
    "\n",
    "The completion is a list of *Completion* objects, which contain the completion text and the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result with metadata\n",
    "print(\"Results:\\n\")\n",
    "print(result)\n",
    "print(\"\\n###\\n\")\n",
    "\n",
    "# Display only the completion\n",
    "print(\"Compeltion:\\n\" + result.completions[0].completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are lots of available parameters\n",
    "The *CompletionRequest* has many parameters that can be set to change the behaviour of the model.\n",
    "\n",
    "You can read more about the parameters in our API documentation.\n",
    "https://docs.aleph-alpha.com/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = Prompt(\"Q: What is AI? A:\")\n",
    "request = CompletionRequest(\n",
    "    prompt = prompt,\n",
    "    maximum_tokens = 20, \n",
    "    temperature = 0, \n",
    "    top_k = 0, \n",
    "    top_p = 0, \n",
    "    presence_penalty = 0, \n",
    "    frequency_penalty = 0, \n",
    "    repetition_penalties_include_prompt = False, \n",
    "    use_multiplicative_presence_penalty = False, \n",
    "    penalty_bias = None, \n",
    "    penalty_exceptions = None, \n",
    "    penalty_exceptions_include_stop_sequences = None, \n",
    "    best_of = None, n = 1, logit_bias = None, \n",
    "    log_probs = None, \n",
    "    stop_sequences = [\"Q:\"], \n",
    "    tokens = False, \n",
    "    disable_optimizations = False\n",
    "    )\n",
    "result = model.complete(request)\n",
    "print(result.completions[0].completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
