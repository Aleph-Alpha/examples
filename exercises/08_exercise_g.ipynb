{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Aleph-Alpha/examples/blob/main/exercises/08_exercise_g.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise G: Create a Demo for Aleph Alpha Technology\n",
    "Finally, in this notebook we will try to create a demo application with a small interface\n",
    "\n",
    "This will help to assess how good a task can be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aleph_alpha_client gradio\n",
    "\n",
    "from typing import Sequence\n",
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient, AlephAlphaModel, SemanticEmbeddingRequest, SemanticRepresentation, Prompt, SummarizationRequest, CompletionRequest, EvaluationRequest, Document\n",
    "import gradio as gr\n",
    "\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model\n",
    "search_model = AlephAlphaModel.from_model_name(\"luminous-base\", token=\"YOUR_TOKEN\")\n",
    "\n",
    "model = AlephAlphaModel.from_model_name(\"luminous-extended\", token= \"YOUR_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined functions\n",
    "To make life a bit easier for you we have defined a few functions that you can use in this notebook.\n",
    "\n",
    "\n",
    "They are described in this table:\n",
    "|function|description|\n",
    "|---|---|\n",
    "|`embed_symmetric`| Embeds a text using the symmetric model|\n",
    "|`embed_query`| Embeds a query using the asymmetric model|\n",
    "|`embed_document`| Embeds a document using the asymmetric model|\n",
    "|`cosine_similarity`| Calculates the cosine similarity between two vectors|\n",
    "|`generate_summary`| Generates a summary of a document|\n",
    "|`split_text`| Splits a text into paragraphs|\n",
    "|`evaluate`| Uses the evaluate functionality of luminous to evaluate how good a completion fits to a query|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for symmetric embeddings \n",
    "def embed_symmetric(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Symmetric)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function for asymmetric embeddings of Queries\n",
    "def embed_query(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Query)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function for asymmetric embeddings of Documents\n",
    "def embed_document(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Document)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function to calculate similarity\n",
    "def cosine_similarity(v1: Sequence[float], v2: Sequence[float]) -> float:\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "# function for getting a summary\n",
    "def generate_summary(text: str):\n",
    "    request = SummarizationRequest(document=Document.from_text(text))\n",
    "    result = model.summarize(request)\n",
    "    return result.summary\n",
    "\n",
    "# function that splits text by paragraphs\n",
    "def split_text(text: str):\n",
    "    return text.split(\"\\n\\n\")\n",
    "\n",
    "# function that evaluate two texts\n",
    "def evaluate(text1: str, text2: str):\n",
    "    request = EvaluationRequest(prompt=Prompt.from_text(text1), completion_expected=text2)\n",
    "    result = model.evaluate(request)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a small data extraction demo\n",
    "We will create a small demo that extracts the most relevant information from emails. We will visualize the results in a small interface using gradio. \n",
    "\n",
    "The data we will extract is:\n",
    "- The sender\n",
    "- The receiver\n",
    "- The intent of the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : write a prompt that extracts the sender and the receiver from the email.\n",
    "# Keep in mind that the prompt should be able to handle multiple emails and that there may be no information about the sender or the receiver.\n",
    "\n",
    "def extract_sender(text: str):\n",
    "    prompt = \"\"\"Write a prompt that extracts the sender from the email.\"\"\" #TODO\n",
    "    \n",
    "    request = CompletionRequest(prompt=Prompt.from_text(prompt), stop_sequences=[\"###\"], max_tokens=20)\n",
    "    completion = model.complete(request).completions[0].completion\n",
    "    sender = completion\n",
    "    return sender\n",
    "\n",
    "def extract_receiver(text: str):\n",
    "    prompt = \"\"\"Write a prompt that extracts the receiver from the email.\"\"\" #TODO\n",
    "    \n",
    "    request = CompletionRequest(prompt=Prompt.from_text(prompt), stop_sequences=[\"###\"], max_tokens=20)\n",
    "    completion = model.complete(request).completions[0].completion\n",
    "    receiver = completion\n",
    "    return receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : write a prompt that extracts the intent from the email.\n",
    "def extract_intent(text: str):\n",
    "    prompt = \"\"\"Write a prompt that extracts the intent from the email.\"\"\" #TODO\n",
    "    \n",
    "    request = CompletionRequest(prompt=Prompt.from_text(prompt), stop_sequences=[\"###\"], max_tokens=20)\n",
    "    completion = model.complete(request).completions[0].completion\n",
    "    intent = completion\n",
    "    return intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper fuction that runs the above functions and returns the results\n",
    "def run(text: str):\n",
    "    sender = extract_sender(text)\n",
    "    receiver = extract_receiver(text)\n",
    "    intent = extract_intent(text)\n",
    "    return sender, receiver, intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results\n",
    "AI can be hard to understand. To make it easier for us to understand the results we will visualize them using gradio. Gradio is a library that allows you to create a small interface for your AI model. You can find more information about gradio [here](https://gradio.app/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Interface that accepts a text and returns the sender, receiver and intent\n",
    "interface = gr.Interface(\n",
    "    fn=run,\n",
    "    inputs=gr.components.Textbox(lines=10, placeholder=\"Enter your email here\"),\n",
    "    outputs=[\n",
    "        gr.components.Textbox(label=\"Sender\"),\n",
    "        gr.components.Textbox(label=\"Receiver\"),\n",
    "        gr.components.Textbox(label=\"Intent\"),\n",
    "    ],\n",
    "    title=\"Email Intent Extraction\",\n",
    "    description=\"This model extracts the sender, receiver and intent from an email.\"\n",
    ")\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
