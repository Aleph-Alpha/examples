{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Aleph-Alpha/examples/blob/main/exercises/08_exercise_g.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise G: Create an evaluation for a prompt\n",
    "Finally, in this notebook we will try to create an evaluation script for a simple Q&A task.\n",
    "\n",
    "This will help to assess how good a task can be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aleph_alpha_client\n",
    "from typing import Sequence\n",
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient, AlephAlphaModel, SemanticEmbeddingRequest, SemanticRepresentation, Prompt, SummarizationRequest, CompletionRequest, EvaluationRequest, Document\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model\n",
    "search_model = AlephAlphaModel.from_model_name(\"luminous-base\",\"API_TOKEN\")\n",
    "\n",
    "model = AlephAlphaModel.from_model_name(\"luminous-extended\",\"API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined functions\n",
    "To make life a bit easier for you we have defined a few functions that you can use in this notebook.\n",
    "\n",
    "\n",
    "They are described in this table:\n",
    "|function|description|\n",
    "|---|---|\n",
    "|`embed_symmetric`| Embeds a text using the symmetric model|\n",
    "|`embed_query`| Embeds a query using the asymmetric model|\n",
    "|`embed_document`| Embeds a document using the asymmetric model|\n",
    "|`cosine_similarity`| Calculates the cosine similarity between two vectors|\n",
    "|`generate_summary`| Generates a summary of a document|\n",
    "|`split_text`| Splits a text into paragraphs|\n",
    "|`evaluate`| Uses the evaluate functionality of luminous to evaluate how good a completion fits to a query|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for symmetric embeddings \n",
    "def embed_symmetric(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Symmetric)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function for asymmetric embeddings of Queries\n",
    "def embed_query(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Query)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function for asymmetric embeddings of Documents\n",
    "def embed_document(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Document)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function to calculate similarity\n",
    "def cosine_similarity(v1: Sequence[float], v2: Sequence[float]) -> float:\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "# function for getting a summary\n",
    "def generate_summary(text: str):\n",
    "    request = SummarizationRequest(document=Document.from_text(text))\n",
    "    result = model.summarize(request)\n",
    "    return result.summary\n",
    "\n",
    "# function that splits text by paragraphs\n",
    "def split_text(text: str):\n",
    "    return text.split(\"\\n\\n\")\n",
    "\n",
    "# function that evaluate two texts\n",
    "def evaluate(text1: str, text2: str):\n",
    "    request = EvaluationRequest(prompt=Prompt.from_text(text1), completion_expected=text2)\n",
    "    result = model.evaluate(request)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional functions\n",
    "Here are three additional functions.\n",
    "\n",
    "They are for easier use of search as well as question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-prompt used for the question answering task\n",
    "pre_prompt = \"This system answers questions based on a text.\\nText:A concept of design science was introduced in 1957 by R. Buckminster Fuller[1][2] who defined it as a systematic form of designing.\\nQUestion: When was the concept of design science introduced?\\nAnswer: 1957\\n###\\nText: The Function-Behaviour-Structure ontology – or short, the FBS ontology – is an ontology of design objects, i.e. things that have been or can be designed. The Function-Behaviour-Structure ontology conceptualizes design objects in three ontological categories.\\nQuestion: How many categories are there?\\nAnswer: 3\\n###\\n\"\n",
    "\n",
    "# embeds a list of texts\n",
    "def embed_document_texts(texts: Sequence[str]):\n",
    "    return [embed_document(text) for text in texts]\n",
    "\n",
    "# returns the top-scoring documents for a query\n",
    "def search(query: str, embedded_documents, top_n: int = 1):\n",
    "    embedded_query = embed_query(query)\n",
    "    scores = [cosine_similarity(embedded_query, embedded_document) for embedded_document in embedded_documents]\n",
    "    return sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "\n",
    "# function that returns the answer to a question and uses the search function\n",
    "def answer_question(question: str, embedded_documents):\n",
    "    context = search(question, top_n=1, embedded_documents=embedded_documents)[0]\n",
    "    req = CompletionRequest(prompt=Prompt.from_text(pre_prompt + f\"Context: \\\"{context}\\\"\\nQuestion: \\\"{question}\\\"\\nAnswer:\"), stop_sequences=[\"###\", \"\\n\"])\n",
    "    result = model.complete(req)\n",
    "    return result.completions[0].completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Here we have some texts and samples can be used to test your evaluation function.\n",
    "\n",
    "In the *qa_samples*-object you can find a few samples of questions to the text with answers and the correct context.\n",
    "\n",
    "Feel free to add more samples if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_texts = [\n",
    "    \"WhatsApp Messenger, or simply WhatsApp, is an internationally available freeware, cross-platform centralized instant messaging (IM) and voice-over-IP (VoIP) service owned by American company Meta Platforms (formerly Facebook). It was first released in 2009.\",\n",
    "    \"Mountain View is a city in Santa Clara County, California,[11] United States. Named for its views of the Santa Cruz Mountains,[12] it has a population of 82,376.[8]\",\n",
    "    \"The opposite of high tech is low technology, referring to simple, often traditional or mechanical technology; for example, a slide rule is a low-tech calculating device.[5][6][7] When high tech becomes old, it becomes low tech, for example vacuum tube electronics.\",\n",
    "    \"A startup or start-up is a company or project undertaken by an entrepreneur to seek, develop, and validate a scalable business model.[1][2] While entrepreneurship refers to all new businesses, including self-employment and businesses that never intend to become registered, startups refer to new businesses that intend to grow large beyond the solo founder.\",\n",
    "    ]\n",
    "\n",
    "\n",
    "embedded_texts = embed_document_texts(qa_texts)\n",
    "\n",
    "qa_samples = [{\n",
    "    \"question\": \"When was WhatsApp released?\", \n",
    "    \"correct_answer\" : \"2009\", \n",
    "    \"correct_context\" : 0},\n",
    "    {\n",
    "    \"question\": \"In which state is Mountain View located?\", \n",
    "    \"correct_answer\" : \"California\", \n",
    "    \"correct_context\" : 1},\n",
    "    {\n",
    "    \"question\": \"What is the opposite of high tech?\", \n",
    "    \"correct_answer\" : \"Low tech\", \n",
    "    \"correct_context\" : 2},\n",
    "    {\n",
    "    \"question\": \"Who undertakes a startup?\", \n",
    "    \"correct_answer\" : \"Entrepreneur\", \n",
    "    \"correct_context\" : 3},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if our function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question(\"What is the opposite of high tech?\", embedded_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: \n",
    "Write an automated evaluation for both the search as well as the answering function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that runs through all the qa samples and checks if they return the correct answer\n",
    "def eval_test_set():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
