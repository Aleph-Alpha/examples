{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Aleph-Alpha/examples/blob/main/exercises/04_exercise_c.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise C: Some Optimizations\n",
    "\n",
    "Use your prompting skills to do some optimization.\n",
    "\n",
    "How would you test if the prompt is working well?\n",
    "\n",
    "Try to use the client to automate as many steps as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aleph_alpha_client in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (2.4.3)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (1.26.9)\n",
      "Requirement already satisfied: requests>=2.28 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install aleph_alpha_client\n",
    "from aleph_alpha_client import AlephAlphaModel, AlephAlphaClient, CompletionRequest, Prompt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model\n",
    "model = AlephAlphaModel.from_model_name(\"luminous-extended\",\"API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple functions for embedding and searching\n",
    "\n",
    "Here you can see a few simple functions that can be used to run different queries in parallel.\n",
    "\n",
    "Often it makes sense to define a specific few_shot prompt for a specific task, so that task can be repeated easily.\n",
    "\n",
    "This way, a new request for that task can ben made and easily executed.\n",
    "\n",
    "The few_shot should contain a good structure and few-shot examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for running multiple completions\n",
    "def run_prompts_from_list(few_shot:str, list_of_queries):\n",
    "    # iterate through all tasks\n",
    "    for query in list_of_queries:\n",
    "        #create the prompt and request\n",
    "        prompt = Prompt(few_shot + query)\n",
    "        request = CompletionRequest(prompt=prompt, maximum_tokens=50, stop_sequences=[\"###\"])\n",
    "        # run the single task\n",
    "        result = model.complete(request)\n",
    "        #display the result\n",
    "        print(result.completions[0].completion)\n",
    "\n",
    "# create a prompt\n",
    "prompt = Prompt(\"\"\"Define your prompt here.\n",
    "                It can also be multi-line.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks: \n",
    "1. Copy your prompt from the last exercise and see if you can optimize it\n",
    "    - You can use the `%%time` magic to see how long it takes to run\n",
    "    - try experimenting with instructions and examples. Which work best?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 401] {\"error\":\"InvalidToken\",\"code\":\"UNAUTHENTICATED\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/home/markus/Code/templates/exercises/04_exercise_c.ipynb Cell 8\u001b[0m in \u001b[0;36mrun_prompts_from_list\u001b[0;34m(few_shot, list_of_queries)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/04_exercise_c.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m request \u001b[39m=\u001b[39m CompletionRequest(prompt\u001b[39m=\u001b[39mprompt, maximum_tokens\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, stop_sequences\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m###\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/04_exercise_c.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# run the single task\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/04_exercise_c.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mcomplete(request)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/04_exercise_c.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#display the result\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/04_exercise_c.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39mcompletions[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcompletion)\n",
      "File \u001b[0;32m~/anaconda3/envs/playground/lib/python3.9/site-packages/aleph_alpha_client/aleph_alpha_model.py:92\u001b[0m, in \u001b[0;36mAlephAlphaModel.complete\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplete\u001b[39m(\u001b[39mself\u001b[39m, request: CompletionRequest) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CompletionResponse:\n\u001b[0;32m---> 92\u001b[0m     response_json \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcomplete(\n\u001b[1;32m     93\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     94\u001b[0m         hosting\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhosting,\n\u001b[1;32m     95\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mas_request_dict(request),\n\u001b[1;32m     96\u001b[0m         checkpoint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheckpoint_name\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m CompletionResponse\u001b[39m.\u001b[39mfrom_json(response_json)\n",
      "File \u001b[0;32m~/anaconda3/envs/playground/lib/python3.9/site-packages/aleph_alpha_client/aleph_alpha_client.py:371\u001b[0m, in \u001b[0;36mAlephAlphaClient.complete\u001b[0;34m(self, model, prompt, hosting, maximum_tokens, temperature, top_k, top_p, presence_penalty, frequency_penalty, repetition_penalties_include_prompt, use_multiplicative_presence_penalty, penalty_bias, penalty_exceptions, penalty_exceptions_include_stop_sequences, best_of, n, logit_bias, log_probs, stop_sequences, tokens, disable_optimizations, checkpoint)\u001b[0m\n\u001b[1;32m    363\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m checkpoint\n\u001b[1;32m    365\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_request(\n\u001b[1;32m    366\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcomplete\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     headers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_headers,\n\u001b[1;32m    368\u001b[0m     params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    369\u001b[0m     json\u001b[39m=\u001b[39mpayload,\n\u001b[1;32m    370\u001b[0m )\n\u001b[0;32m--> 371\u001b[0m response_json \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_translate_errors(response)\u001b[39m.\u001b[39mjson()\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m response_json\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39moptimized_prompt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m     \u001b[39m# Return a message to the user that we optimized their prompt\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    375\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mWe optimized your prompt before sending it to the model. The optimized prompt is available at result[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moptimized_prompt\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]. If you do not want these optimizations applied, you can pass the disable_optimizations flag to your request.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    376\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/playground/lib/python3.9/site-packages/aleph_alpha_client/aleph_alpha_client.py:776\u001b[0m, in \u001b[0;36mAlephAlphaClient._translate_errors\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    775\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[0;32m--> 776\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mPermissionError\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    777\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m402\u001b[39m:\n\u001b[1;32m    778\u001b[0m     \u001b[39mraise\u001b[39;00m QuotaError(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 401] {\"error\":\"InvalidToken\",\"code\":\"UNAUTHENTICATED\"}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a lfew-shot prompt that works well on the task\n",
    "few_shot = \"\"\"This system generates titles for articles.\n",
    "###\n",
    "Text: Heidelberg is a city in Germany. It is beautiful and has a wonderful castle and many other sights worth visiting.\n",
    "Title: Heidelberg, the beautiful city\n",
    "###\n",
    "Text: This is an interpretation of Alice in Wonderland. Alice is a young girl who falls down a rabbit hole and finds herself in a strange world.\n",
    "Title: The tale of young Alice\n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "# create a list of queries to solve\n",
    "queries = [\n",
    "    \"Text: Dinosaurs roamed the earth millions of years ago. They were huge and scary. They were also very interesting.\\nTitle:\",\n",
    "    \"Text: The sun is a star. It is very hot and gives us light and warmth. It is also very big.\\nTitle:\",\n",
    "    \"Text: The works of Dionysius the Areopagite are a collection of writings from the 5th century. They are very important for the history of Christianity.\\nTitle:\",\n",
    "]\n",
    "\n",
    "# run the prompts\n",
    "run_prompts_from_list(few_shot, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
