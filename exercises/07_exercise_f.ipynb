{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Aleph-Alpha/examples/blob/main/exercises/07_exercise_f.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise F: Combined applications\n",
    "\n",
    "In this notebook we will learn how to combine functionalities to create a simple application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aleph_alpha_client\n",
    "from typing import Sequence\n",
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient, AlephAlphaModel, SemanticEmbeddingRequest, SemanticRepresentation, Prompt, SummarizationRequest, CompletionRequest, EvaluationRequest\n",
    "import math\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are using both completion and search in this notebook, we define two models:\n",
    "- One for search with Luminous Explore (luminous-base)\n",
    "- One for completion (luminous-extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model\n",
    "search_model = AlephAlphaModel.from_model_name(\"luminous-base\",\"API_TOKEN\")\n",
    "\n",
    "model = AlephAlphaModel.from_model_name(\"luminous-extended\",\"API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined functions\n",
    "To make life a bit easier for you, we have defined a few functions that you can use in this notebook.\n",
    "\n",
    "\n",
    "They are described in the table below:\n",
    "|function|description|\n",
    "|---|---|\n",
    "|`embed_symmetric`| Embeds a text using the symmetric model|\n",
    "|`embed_query`| Embeds a query using the asymmetric model|\n",
    "|`embed_document`| Embeds a document using the asymmetric model|\n",
    "|`cosine_similarity`| Calculates the cosine similarity between two vectors|\n",
    "|`generate_summary`| Generates a summary of a document|\n",
    "|`split_text`| Splits a text into paragraphs|\n",
    "|`evaluate`| Uses the evaluate functionality of luminous to evaluate how good a completion fits to a query|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for symmetric embeddings \n",
    "def embed_symmetric(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Symmetric)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function for asymmetric embeddings of Queries\n",
    "def embed_query(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Query)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function for asymmetric embeddings of Documents\n",
    "def embed_document(text: str):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Document)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function to calculate similarity\n",
    "def cosine_similarity(v1: Sequence[float], v2: Sequence[float]) -> float:\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "# function for getting a summary\n",
    "def generate_summary(text: str):\n",
    "    request = SummarizationRequest(prompt=Prompt.from_text(text))\n",
    "    result = model.summarize(request)\n",
    "    return result.summary\n",
    "\n",
    "# function that splits text by paragraphs\n",
    "def split_text(text: str):\n",
    "    return text.split(\"\\n\\n\")\n",
    "\n",
    "# function that evaluate two texts\n",
    "def evaluate(text1: str, text2: str):\n",
    "    request = EvaluationRequest(prompt=Prompt.from_text(text1), completion_expected=text2)\n",
    "    result = model.evaluate(request)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "Create a function that searches a list of texts based on a question and then generates an answer.\n",
    "- Use search to find the most relevant text\n",
    "- Use a completion request with your own prompt to generate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_to_search = [\n",
    "    \"The judiciary of Poland (Polish: sądownictwo w Polsce) are the authorities exercising the judicial power of the Polish state on the basis of Chapter 8 of the Constitution of Poland.[a] As in almost all countries of continental Europe, the Polish judiciary operates within the framework of civil law.The courts (sądy), designated by the Constitution as those exercising the administration of justice (wymiar sprawiedliwości), are the bodies that review the vast majority of cases, with the exception of those specifically assigned to the two tribunals (trybunały). \",\n",
    "    \"Nicholas Blake 'Nick' Solak (born January 11, 1995) is an American professional baseball second baseman and outfielder for the Texas Rangers of Major League Baseball (MLB). Solak attended Naperville North High School in Naperville, Illinois, and the University of Louisville in Louisville, Kentucky.\",\n",
    "    \"Die Buddhistenkrise war ein Zeitraum politisch-religiöser Anspannungen in Südvietnam vom 8. Mai bis 2. November 1963. Sie wurde durch das Verbot der buddhistischen Flagge durch die Regierung Ngô Đình Diệms ausgelöst, und endete mit einem Putsch der Armee der Republik Vietnam, wobei Ngô Đình Diệm festgenommen und später getötet wurde.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a complicated Task, so try solve one task at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = [embed_document(text) for text in texts_to_search]\n",
    "\n",
    "def search_and_answer(question : str):\n",
    "    \n",
    "    # TODO get the query embeddings of the question and the document embeddings of the texts_to_search\n",
    "    query_embedding = None #ToDo\n",
    "    document_embeddings = None #ToDo\n",
    "    \n",
    "    # TODO calculate the similarity between the question and the texts\n",
    "    scores = []\n",
    "    for document in document_embeddings:\n",
    "        pass #ToDo\n",
    "    \n",
    "    # select the text with the highest similarity\n",
    "    best_text_index = scores.index(max(scores))\n",
    "    best_text = texts_to_search[best_text_index]\n",
    "    \n",
    "    # TODO create a completion task with the best text\n",
    "    prompt = Prompt.from_text(\"\"\"Write a good QA prompt here\"\"\")\n",
    "    \n",
    "    request = CompletionRequest(prompt=prompt, stop_sequences=[\"\\n\"])\n",
    "    \n",
    "    # call the model to complete the task\n",
    "    result = model.complete(request)    \n",
    "    \n",
    "    # return the answer\n",
    "    return result.completions[0].completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_and_answer(\"Who was Nick?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: \n",
    "Create a function that creates a guided summary of a text.\n",
    "- The function should take a text as input as well as some form of guidance\n",
    "- Tipp: use multiple functions from the previous exercises\n",
    "- There are several ways to solve this task. Try to find a solution that works for you.\n",
    "- Tipp: look at the available functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pulls the data from the web\n",
    "text_link = \"https://raw.githubusercontent.com/Aleph-Alpha/examples/main/exercises/text_to_summarize.txt\"\n",
    "req = requests.get(text_link)\n",
    "text_to_summarize = req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that creates a guided summary of a text.\n",
    "# This is a pretty complicated task, so don't worry if you can't get it to work.\n",
    "# The guidance is a string that contains the content that should be in the summary.\n",
    "def guided_summary(text : str, guidance : str):\n",
    "    \n",
    "    # Split the text into paragraphs\n",
    "    splits = split_text(text)\n",
    "\n",
    "    # TODO embed each of the splits\n",
    "    embeddings = []\n",
    "    for split in splits:\n",
    "        \n",
    "        # TODO get the embedding of the split\n",
    "        split_embedding = None\n",
    "        \n",
    "        embeddings.append(split_embedding)\n",
    "    \n",
    "    # TODO Embed the guidance\n",
    "    embedded_guidance = None\n",
    "    \n",
    "    # calculate a similarity for each of the splits\n",
    "    list_of_scored_splits =  []   # list of tuples (split, score, position)\n",
    "    list_of_scores = []\n",
    "    for i in range(len(splits)):\n",
    "        \n",
    "        # TODO calculate the similarity between the guidance and the split embedding\n",
    "        similarity_score = None\n",
    "        \n",
    "        # add the similarity score to the list of scored splits\n",
    "        list_of_scored_splits.append((splits[i], similarity_score, i))\n",
    "        \n",
    "        # add the similarity score to the list of scores for accessing the top 3\n",
    "        list_of_scores.append(similarity_score)\n",
    "        \n",
    "    \n",
    "    # select the top 5 splits by score\n",
    "    top_5_splits = sorted(list_of_scored_splits, key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    # sort the top 5 splits by position\n",
    "    top_5_splits = sorted(top_5_splits, key=lambda x: x[2])\n",
    "    \n",
    "    # join the top 5 splits into a guided text\n",
    "    guided_text = \"\\n\".join([x[0] for x in top_5_splits])\n",
    "        \n",
    "    # TODO use the guided text to generate a summary\n",
    "    summary = None # ToDo call the generate_summary function\n",
    "    \n",
    "    return summary\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
