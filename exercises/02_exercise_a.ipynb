{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Aleph-Alpha/examples/blob/main/exercises/02_exercise_a.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise A: Try out completion calls\n",
    "\n",
    "In this noteboom we will try out different completion calls.\n",
    "\n",
    "Completion is the main task that is also done in the playground.\n",
    "\n",
    "When using the same parameters as in the playground, we can compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aleph_alpha_client in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (2.4.3)\n",
      "Requirement already satisfied: requests>=2.28 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (2.28.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install aleph_alpha_client\n",
    "from aleph_alpha_client import AlephAlphaModel, AlephAlphaClient, CompletionRequest, Prompt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model\n",
    "model = AlephAlphaModel.from_model_name(\"luminous-extended\",\"API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a prompt for completion\n",
    "Each completion request needs a prompt.\n",
    "\n",
    "The prompt is the instruction to the model what to do.\n",
    "\n",
    "In a CompletionRequest, the model will try to predict the next words based on the prompt.\n",
    "\n",
    "Prompts work best if the contain a good strcuture and few-shot examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 401] {\"error\":\"InvalidToken\",\"code\":\"UNAUTHENTICATED\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/markus/Code/templates/exercises/02_exercise_a.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/02_exercise_a.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m request \u001b[39m=\u001b[39m CompletionRequest(prompt\u001b[39m=\u001b[39mprompt, maximum_tokens\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, stop_sequences\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m###\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m], temperature\u001b[39m=\u001b[39m\u001b[39m0.12\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/02_exercise_a.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# complete the prompt\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/02_exercise_a.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mcomplete(request)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/markus/Code/templates/exercises/02_exercise_a.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39mcompletions[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcompletion)\n",
      "File \u001b[0;32m~/anaconda3/envs/playground/lib/python3.9/site-packages/aleph_alpha_client/aleph_alpha_model.py:92\u001b[0m, in \u001b[0;36mAlephAlphaModel.complete\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplete\u001b[39m(\u001b[39mself\u001b[39m, request: CompletionRequest) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CompletionResponse:\n\u001b[0;32m---> 92\u001b[0m     response_json \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcomplete(\n\u001b[1;32m     93\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     94\u001b[0m         hosting\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhosting,\n\u001b[1;32m     95\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mas_request_dict(request),\n\u001b[1;32m     96\u001b[0m         checkpoint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheckpoint_name\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m CompletionResponse\u001b[39m.\u001b[39mfrom_json(response_json)\n",
      "File \u001b[0;32m~/anaconda3/envs/playground/lib/python3.9/site-packages/aleph_alpha_client/aleph_alpha_client.py:371\u001b[0m, in \u001b[0;36mAlephAlphaClient.complete\u001b[0;34m(self, model, prompt, hosting, maximum_tokens, temperature, top_k, top_p, presence_penalty, frequency_penalty, repetition_penalties_include_prompt, use_multiplicative_presence_penalty, penalty_bias, penalty_exceptions, penalty_exceptions_include_stop_sequences, best_of, n, logit_bias, log_probs, stop_sequences, tokens, disable_optimizations, checkpoint)\u001b[0m\n\u001b[1;32m    363\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m checkpoint\n\u001b[1;32m    365\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_request(\n\u001b[1;32m    366\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcomplete\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     headers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_headers,\n\u001b[1;32m    368\u001b[0m     params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    369\u001b[0m     json\u001b[39m=\u001b[39mpayload,\n\u001b[1;32m    370\u001b[0m )\n\u001b[0;32m--> 371\u001b[0m response_json \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_translate_errors(response)\u001b[39m.\u001b[39mjson()\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m response_json\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39moptimized_prompt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m     \u001b[39m# Return a message to the user that we optimized their prompt\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    375\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mWe optimized your prompt before sending it to the model. The optimized prompt is available at result[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moptimized_prompt\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]. If you do not want these optimizations applied, you can pass the disable_optimizations flag to your request.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    376\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/playground/lib/python3.9/site-packages/aleph_alpha_client/aleph_alpha_client.py:776\u001b[0m, in \u001b[0;36mAlephAlphaClient._translate_errors\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    775\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[0;32m--> 776\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mPermissionError\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    777\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m402\u001b[39m:\n\u001b[1;32m    778\u001b[0m     \u001b[39mraise\u001b[39;00m QuotaError(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 401] {\"error\":\"InvalidToken\",\"code\":\"UNAUTHENTICATED\"}"
     ]
    }
   ],
   "source": [
    "# create a prompt\n",
    "prompt = Prompt(\"\"\"Identify matching keywords for each text.\n",
    "###\n",
    "Text: The \"Whiskey War\" is an ongoing conflict between Denmark and Canada over ownership of Hans Island. The dispute began in 1973, when Denmark and Canada reached an agreement on Greenland's borders. However, no settlement regarding Hans Island could be reached by the time the treaty was signed. Since then both countries have used peaceful means - such as planting their national flag or burying liquor - to draw attention to the disagreement.\n",
    "Keywords: Conflict, Whiskey War, Denmark, Canada, Treaty, Flag, Liquor\n",
    "###\n",
    "Text: NASA launched the Discovery program to explore the solar system. It comprises a series of expeditions that have continued from the program's launch in the 1990s to the present day. In the course of the 16 expeditions launched so far, the Moon, Mars, Mercury and Venus, among others, have been explored. Unlike other space programs, the Discovery program places particular emphasis on cost efficiency, true to the motto: \"faster, better, cheaper\".\n",
    "Keywords: Space program, NASA, Expedition, Cost efficiency, Moon, Mars, Mercury, Venus\n",
    "###\n",
    "Text: Computer vision describes the processing of an image by a machine using external devices (e.g., a scanner) into a digital description of that image for further processing. An example of this is optical character recognition (OCR), the recognition and processing of images containing text. Further processing and final classification of the image is often done using artificial intelligence methods. The goal of this field is to enable computers to process visual tasks that were previously reserved for humans.\n",
    "Keywords:\"\"\")\n",
    "\n",
    "# create a completion request\n",
    "request = CompletionRequest(prompt=prompt, maximum_tokens=32, stop_sequences=[\"###\",\"\\n\"], temperature=0.12)\n",
    "\n",
    "# complete the prompt\n",
    "result = model.complete(request)\n",
    "\n",
    "print(result.completions[0].completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks: \n",
    "1. Try out completion calls with different prompts and see what they do.\n",
    "2. Take a look at the \"result\" and see how it is structured. What Information is contained in the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt\n",
    "prompt = Prompt(\"\")\n",
    "\n",
    "# create a completion request\n",
    "request = CompletionRequest(prompt=prompt, maximum_tokens=20, stop_sequences=[\"Q:\"])\n",
    "\n",
    "# complete the prompt\n",
    "result = model.complete(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(result.completions[0].completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
