{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: A first look into search\n",
    "In this notebook we will take a look at luminous explore.\n",
    "\n",
    "Luminous-Explore is our model for semantic similarity.\n",
    "\n",
    "With explore, you can use the meaning of text to create awesome applications.\n",
    "\n",
    "Try it out below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aleph_alpha_client in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (2.4.3)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (1.26.9)\n",
      "Requirement already satisfied: requests>=2.28 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install aleph_alpha_client\n",
    "\n",
    "# Some addition imports for search\n",
    "from typing import Sequence\n",
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient, AlephAlphaModel, SemanticEmbeddingRequest, SemanticRepresentation, Prompt\n",
    "from IPython.display import Image  \n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model for embedding\n",
    "\n",
    "Our Embedding model is called luminous-explore.\n",
    "\n",
    "However to access its functionalities, it is important to define luminous-base as the used model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model\n",
    "model = AlephAlphaModel.from_model_name(model_name = \"luminous-base\", token=\"API-TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple functions for embedding and searching\n",
    "Here we provide a simple function for embedding text and a simple function for calculating the similarity between two texts.\n",
    "\n",
    "Please take a moment to understand what each function does.\n",
    "\n",
    "The cosine similarity is a measure of similarity between two vectors of an inner product space that measures the cosine of the angle between them.\n",
    "\n",
    "You don't have to understand the details of the code, but you should understand the general idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for symmetric embedding\n",
    "def embed_symmetric(text: str):\n",
    "    # Create an embeddingrequest with the type set to symmetric\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Symmetric)\n",
    "    # create the embedding\n",
    "    result = model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function to calculate similarity\n",
    "def cosine_similarity(v1: Sequence[float], v2: Sequence[float]) -> float:\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using semantic similarity\n",
    "Now we can use the semantic similarity to find similar texts.\n",
    "\n",
    "Let's compare two texts, one in english and one in italian to see how it works.\n",
    "\n",
    "In this case, both sentances have the same meaning. So they should return a high similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9123379711230551\n"
     ]
    }
   ],
   "source": [
    "# define the texts\n",
    "text_a = \"The sun is shining\"\n",
    "text_b = \"Il sole splende\"\n",
    "\n",
    "# show the similarity\n",
    "print(cosine_similarity(embed_symmetric(text_a), embed_symmetric(text_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The embedding\n",
    "Let's also take a look at the embedding itself and how it looks.\n",
    "\n",
    "In the cell below we print the first 100 elements of the embedding.\n",
    "\n",
    "The embedding is 5120 elements long, so printing all of it would be quite a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2265625, 0.71875, -0.076660156, 0.79296875, -0.17480469, -1.9921875, 0.91015625, -1.1484375, 0.42578125, -1.1328125, 1.09375, 0.24804688, 0.85546875, -1.3359375, -0.60546875, -0.96484375, 0.07128906, -0.390625, -1.28125, -0.0009765625, 0.46679688, 1.46875, 0.29492188, 1.234375, 0.40625, -0.5078125, -2.078125, 2.703125, 0.17285156, -1.9609375, 0.6796875, 2.09375, -1.015625, -0.47851562, 1.109375, 0.076660156, -2.3125, -2.65625, -0.000831604, 0.9296875, 0.18945312, -1.109375, 0.44921875, -0.54296875, 1.359375, 0.7734375, 0.796875, 0.953125, -2.34375, -0.48632812, -0.42382812, -0.5625, 1.46875, 0.55078125, 0.18554688, 0.20214844, -0.040283203, -0.22558594, 0.4453125, 1.359375, 0.2734375, -2.578125, -0.25585938, -0.07519531, 0.15136719, -0.39453125, -1.1875, 0.87890625, 0.038330078, -1.5625, 0.048339844, 0.8203125, 1.2734375, 0.022094727, 1.1328125, -0.033935547, 1.6796875, -0.22070312, 0.06591797, -0.032226562, -0.67578125, -2.078125, -2.234375, -1.34375, -0.53515625, -1.4609375, -0.29882812, -1.28125, 0.111328125, -0.63671875, 1.2265625, 0.16210938, -0.19726562, 0.65625, -1.8359375, -0.053222656, -0.22460938, 0.48828125, -2.21875, -1.4921875]\n",
      "\n",
      "\n",
      "[1.296875, 0.30859375, -0.36914062, 1.40625, -0.16113281, -1.3125, -0.26171875, -1.4453125, 0.3125, -0.98828125, 1.015625, 0.11230469, 0.94921875, -0.85546875, -0.25195312, 0.9453125, -0.15917969, -0.18652344, -1.3984375, -0.107421875, 0.07910156, 1.7265625, 0.49414062, 0.88671875, 0.67578125, -0.671875, -2.296875, 1.9765625, -0.13769531, -1.984375, 0.67578125, 1.9375, -1.53125, -0.9296875, 1.9453125, -0.24707031, -2.3125, -2.15625, 0.7734375, 0.85546875, 0.5703125, -0.73828125, -0.06640625, -1.4140625, 1.5625, 0.94921875, 0.13769531, 2.109375, -1.671875, 0.050048828, -0.43554688, 0.12451172, 1.1484375, 0.47460938, 0.53515625, 0.07910156, -0.35742188, -0.7421875, 0.48046875, 2.375, 0.41210938, -2.84375, -0.29296875, 0.53125, 0.123046875, -1.140625, -1.203125, -0.25390625, 0.06738281, -1.6875, -0.23242188, 0.97265625, 0.97265625, 0.01159668, 1.0859375, -0.60546875, 2.125, 0.33398438, -0.2578125, 0.61328125, -0.49609375, -0.9296875, -2.1875, -1.2734375, -0.5703125, -2.15625, -0.6328125, -0.021606445, 0.2421875, -0.28125, 1.5234375, 0.75, -0.5, 0.328125, -1.4296875, 0.030029297, -0.68359375, 0.6640625, -1.6015625, -1.515625]\n",
      "CPU times: user 15.4 ms, sys: 583 Âµs, total: 16 ms\n",
      "Wall time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(embed_symmetric(text_a)[:100])\n",
    "print(\"\\n\")\n",
    "print(embed_symmetric(text_b)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Similarity\n",
    "Amazingly, as luminous supports multi-modal input, we can even semantically compare texts to images.\n",
    "\n",
    "This is not an explicitly developed feature, but rather an emergent property of the model.\n",
    "\n",
    "*Please keep in mind, that multi-modal semantic similarity is probably less robust than text to text similarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1200/1*HunNdlTmoPj8EKpl-jqvBA.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an image from a url\n",
    "url = \"https://cdn-images-1.medium.com/max/1200/1*HunNdlTmoPj8EKpl-jqvBA.png\"\n",
    "\n",
    "# put the image into a prompt\n",
    "image_prompt = ImagePrompt.from_url(url)\n",
    "\n",
    "# display the image from the url\n",
    "Image(url=url, width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for the psotive example is: 0.5610950285813592\n",
      "The score for the psotive example is: 0.05519817023842499\n"
     ]
    }
   ],
   "source": [
    "positive_example = \"A neural network Architecture with Attention and Embeddings\"\n",
    "negative_example = \"An image of a beatuiful beach\"\n",
    "\n",
    "print(f\"The score for the psotive example is: {cosine_similarity(embed_symmetric(positive_example), embed_symmetric(image_prompt))}\")\n",
    "print(f\"The score for the psotive example is: {cosine_similarity(embed_symmetric(negative_example), embed_symmetric(image_prompt))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
