{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Simple Search\n",
    "\n",
    "In this notebook you learn how to compare text using semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Install the client\n",
    "You can skip this step, if you have already installed the `aleph_alpha_client`. Make sure you have the [latest pip version](https://pip.pypa.io/en/stable/installation/) installed before proceeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aleph_alpha_client in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (2.8.3)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (1.26.9)\n",
      "Requirement already satisfied: aiodns>=3.0.0 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.28 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (2.28.1)\n",
      "Requirement already satisfied: aiohttp>=3.8.3 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aleph_alpha_client) (3.8.3)\n",
      "Requirement already satisfied: pycares>=4.0.0 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiodns>=3.0.0->aleph_alpha_client) (4.2.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiohttp>=3.8.3->aleph_alpha_client) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiohttp>=3.8.3->aleph_alpha_client) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiohttp>=3.8.3->aleph_alpha_client) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiohttp>=3.8.3->aleph_alpha_client) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiohttp>=3.8.3->aleph_alpha_client) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiohttp>=3.8.3->aleph_alpha_client) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from aiohttp>=3.8.3->aleph_alpha_client) (6.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from requests>=2.28->aleph_alpha_client) (3.3)\n",
      "Requirement already satisfied: cffi>=1.5.0 in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from pycares>=4.0.0->aiodns>=3.0.0->aleph_alpha_client) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/markus/anaconda3/envs/playground/lib/python3.9/site-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns>=3.0.0->aleph_alpha_client) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install aleph_alpha_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model\n",
    "Instantiate a model by providing the `model_name` and `token` for authentification. If you don't have one already, create one in your [Aleph Alpha profile](https://app.aleph-alpha.com/profile). To use semantic embeddings ([luminous-explore](https://www.aleph-alpha.com/luminous-explore-a-model-for-world-class-semantic-representation)), we need to supply `luminous-base` as the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import AlephAlphaModel\n",
    "import os\n",
    "model = AlephAlphaModel.from_model_name(model_name=\"luminous-base\", token=os.getenv(\"API_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the similarity of two texts\n",
    "\n",
    "To compare two texts, you need to embed both and calculate the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) between them. For demonstration purposes we prepared helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import SemanticEmbeddingRequest, SemanticRepresentation, Prompt\n",
    "from typing import Sequence\n",
    "import math\n",
    "\n",
    "# helper function for symmetric embedding\n",
    "def embed(text: str, representation: SemanticRepresentation):\n",
    "    # Create a symmetric SemanticEmbeddingRequest\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=representation)\n",
    "    semantic_embedding = model.semantic_embed(request)\n",
    "    return semantic_embedding.embedding\n",
    "\n",
    "# helper function to calculate similarity\n",
    "def cosine_similarity(v1: Sequence[float], v2: Sequence[float]) -> float:\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using semantic similarity\n",
    "Now we can use the semantic similarity to find similar texts.\n",
    "\n",
    "Let's compare two texts, one in English and one in Italian to see how it works.\n",
    "\n",
    "In this case, both sentences have the same meaning. So they should return a high similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9123379711230551\n"
     ]
    }
   ],
   "source": [
    "# define the texts\n",
    "text_a = \"The sun is shining\"\n",
    "text_b = \"Il sole splende\"\n",
    "\n",
    "# show the similarity\n",
    "print(cosine_similarity(embed(text_a, SemanticRepresentation.Symmetric), embed(text_b, SemanticRepresentation.Symmetric)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The embedding\n",
    "Let's also take a look at the embedding itself and how it looks.\n",
    "\n",
    "In the cell below we print the first 100 elements of the embedding.\n",
    "\n",
    "The embedding is 5120 elements long, so printing all of it would be quite a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2265625, 0.71875, -0.076660156, 0.79296875, -0.17480469, -1.9921875, 0.91015625, -1.1484375, 0.42578125, -1.1328125, 1.09375, 0.24804688, 0.85546875, -1.3359375, -0.60546875, -0.96484375, 0.07128906, -0.390625, -1.28125, -0.0009765625, 0.46679688, 1.46875, 0.29492188, 1.234375, 0.40625, -0.5078125, -2.078125, 2.703125, 0.17285156, -1.9609375, 0.6796875, 2.09375, -1.015625, -0.47851562, 1.109375, 0.076660156, -2.3125, -2.65625, -0.000831604, 0.9296875, 0.18945312, -1.109375, 0.44921875, -0.54296875, 1.359375, 0.7734375, 0.796875, 0.953125, -2.34375, -0.48632812, -0.42382812, -0.5625, 1.46875, 0.55078125, 0.18554688, 0.20214844, -0.040283203, -0.22558594, 0.4453125, 1.359375, 0.2734375, -2.578125, -0.25585938, -0.07519531, 0.15136719, -0.39453125, -1.1875, 0.87890625, 0.038330078, -1.5625, 0.048339844, 0.8203125, 1.2734375, 0.022094727, 1.1328125, -0.033935547, 1.6796875, -0.22070312, 0.06591797, -0.032226562, -0.67578125, -2.078125, -2.234375, -1.34375, -0.53515625, -1.4609375, -0.29882812, -1.28125, 0.111328125, -0.63671875, 1.2265625, 0.16210938, -0.19726562, 0.65625, -1.8359375, -0.053222656, -0.22460938, 0.48828125, -2.21875, -1.4921875] \n",
      "\n",
      "[1.296875, 0.30859375, -0.36914062, 1.40625, -0.16113281, -1.3125, -0.26171875, -1.4453125, 0.3125, -0.98828125, 1.015625, 0.11230469, 0.94921875, -0.85546875, -0.25195312, 0.9453125, -0.15917969, -0.18652344, -1.3984375, -0.107421875, 0.07910156, 1.7265625, 0.49414062, 0.88671875, 0.67578125, -0.671875, -2.296875, 1.9765625, -0.13769531, -1.984375, 0.67578125, 1.9375, -1.53125, -0.9296875, 1.9453125, -0.24707031, -2.3125, -2.15625, 0.7734375, 0.85546875, 0.5703125, -0.73828125, -0.06640625, -1.4140625, 1.5625, 0.94921875, 0.13769531, 2.109375, -1.671875, 0.050048828, -0.43554688, 0.12451172, 1.1484375, 0.47460938, 0.53515625, 0.07910156, -0.35742188, -0.7421875, 0.48046875, 2.375, 0.41210938, -2.84375, -0.29296875, 0.53125, 0.123046875, -1.140625, -1.203125, -0.25390625, 0.06738281, -1.6875, -0.23242188, 0.97265625, 0.97265625, 0.01159668, 1.0859375, -0.60546875, 2.125, 0.33398438, -0.2578125, 0.61328125, -0.49609375, -0.9296875, -2.1875, -1.2734375, -0.5703125, -2.15625, -0.6328125, -0.021606445, 0.2421875, -0.28125, 1.5234375, 0.75, -0.5, 0.328125, -1.4296875, 0.030029297, -0.68359375, 0.6640625, -1.6015625, -1.515625]\n",
      "CPU times: user 7.04 ms, sys: 9.7 ms, total: 16.7 ms\n",
      "Wall time: 779 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(embed(text_a, SemanticRepresentation.Symmetric)[:100], \"\\n\")\n",
    "print(embed(text_b, SemanticRepresentation.Symmetric)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal Similarity\n",
    "Amazingly, as luminous supports multimodal input, we can even semantically compare texts to images with Luminous Explore.\n",
    "\n",
    "This is not an explicitly developed feature but rather an emergent property of the model.\n",
    "\n",
    "*Please keep in mind, that multi-modal semantic similarity is probably less robust than text to text similarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1200/1*HunNdlTmoPj8EKpl-jqvBA.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for the positive example is: 0.562357064961456\n",
      "The score for the neagtive example is: 0.05955637145813491\n"
     ]
    }
   ],
   "source": [
    "from aleph_alpha_client import ImagePrompt\n",
    "from IPython.display import Image\n",
    "\n",
    "url = \"https://cdn-images-1.medium.com/max/1200/1*HunNdlTmoPj8EKpl-jqvBA.png\"\n",
    "prompt = ImagePrompt.from_url(url)\n",
    "positive_text = \"A neural network Architecture with Attention and Embeddings\"\n",
    "negative_text = \"An image of a beatuiful beach\"\n",
    "positive_embedding = cosine_similarity(embed(positive_text, SemanticRepresentation.Symmetric), embed(prompt, SemanticRepresentation.Symmetric))\n",
    "negative_embedding = cosine_similarity(embed(negative_text, SemanticRepresentation.Symmetric), embed(prompt, SemanticRepresentation.Symmetric))\n",
    "\n",
    "# print the Image and calculated embeddings\n",
    "display(Image(url=url, width=300, height=300))\n",
    "print(f\"The score for the positive example is: {positive_embedding}\")\n",
    "print(f\"The score for the neagtive example is: {negative_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
