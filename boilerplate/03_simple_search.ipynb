{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: A first look into search\n",
    "In this notebook we will take a look at Luminous Explore.\n",
    "\n",
    "Luminous Explore is our model for semantic similarity.\n",
    "\n",
    "With Luminous Explore you can use the meaning of text to create awesome applications.\n",
    "\n",
    "Try it out below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aleph_alpha_client\n",
    "\n",
    "# Some additional imports for search with Luminous Explore\n",
    "from typing import Sequence\n",
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient, AlephAlphaModel, SemanticEmbeddingRequest, SemanticRepresentation, Prompt\n",
    "from IPython.display import Image  \n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model for embedding\n",
    "\n",
    "Our Embedding model is called Luminous Explore.\n",
    "\n",
    "However to access its functionalities, it is important to define luminous-base as the used model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client and model\n",
    "model = AlephAlphaModel.from_model_name(model_name=\"luminous-base\", token=\"API-TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple functions for embedding and searching\n",
    "Here we provide a simple function for embedding text and a simple function for calculating the similarity between two texts.\n",
    "\n",
    "Please take a moment to understand what each function does.\n",
    "\n",
    "The cosine similarity is a measure of similarity between two vectors of an inner product space that measures the cosine of the angle between them.\n",
    "\n",
    "You don't have to understand the details of the code, but you should understand the general idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for symmetric embedding\n",
    "def embed_symmetric(text: str):\n",
    "    # Create an embeddingrequest with the type set to symmetric\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Symmetric)\n",
    "    # create the embedding\n",
    "    result = model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function to calculate similarity\n",
    "def cosine_similarity(v1: Sequence[float], v2: Sequence[float]) -> float:\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using semantic similarity\n",
    "Now we can use the semantic similarity to find similar texts.\n",
    "\n",
    "Let's compare two texts, one in English and one in Italian to see how it works.\n",
    "\n",
    "In this case, both sentences have the same meaning. So they should return a high similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the texts\n",
    "text_a = \"The sun is shining\"\n",
    "text_b = \"Il sole splende\"\n",
    "\n",
    "# show the similarity\n",
    "print(cosine_similarity(embed_symmetric(text_a), embed_symmetric(text_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The embedding\n",
    "Let's also take a look at the embedding itself and how it looks.\n",
    "\n",
    "In the cell below we print the first 100 elements of the embedding.\n",
    "\n",
    "The embedding is 5120 elements long, so printing all of it would be quite a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(embed_symmetric(text_a)[:100])\n",
    "print(\"\\n\")\n",
    "print(embed_symmetric(text_b)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Similarity\n",
    "Amazingly, as luminous supports multimodal input, we can even semantically compare texts to images with Luminous Explore.\n",
    "\n",
    "This is not an explicitly developed feature but rather an emergent property of the model.\n",
    "\n",
    "*Please keep in mind, that multi-modal semantic similarity is probably less robust than text to text similarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an image from a url\n",
    "url = \"https://cdn-images-1.medium.com/max/1200/1*HunNdlTmoPj8EKpl-jqvBA.png\"\n",
    "\n",
    "# put the image into a prompt\n",
    "image_prompt = ImagePrompt.from_url(url)\n",
    "\n",
    "# display the image from the url\n",
    "Image(url=url, width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a positive and negative text example\n",
    "positive_example = \"A neural network Architecture with Attention and Embeddings\"\n",
    "negative_example = \"An image of a beatuiful beach\"\n",
    "\n",
    "# Calculate the embedding for the positive and negative example\n",
    "print(f\"The score for the positive example is: {cosine_similarity(embed_symmetric(positive_example), embed_symmetric(image_prompt))}\")\n",
    "print(f\"The score for the neagtive example is: {cosine_similarity(embed_symmetric(negative_example), embed_symmetric(image_prompt))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
