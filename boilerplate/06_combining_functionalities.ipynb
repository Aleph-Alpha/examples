{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6: Combined applications\n",
    "\n",
    "In this notebook we will combine functionalities to create a simple application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Install the client\n",
    "You can skip this step, if you have already installed the `aleph_alpha_client`. Make sure you have the [latest pip version](https://pip.pypa.io/en/stable/installation/) installed before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aleph_alpha_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Luminous\n",
    "Instantiate a model by providing the `model_name` and `token` for authentification. If you don't have one already, create one in your [Aleph Alpha profile](https://app.aleph-alpha.com/profile).\n",
    "\n",
    "Because we are using both completion and search in this notebook, we define a model for search as well as completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import AlephAlphaModel\n",
    "model = AlephAlphaModel.from_model_name(model_name=\"luminous-extended\", token=\"API_TOKEN\")\n",
    "search_model = AlephAlphaModel.from_model_name(model_name = \"luminous-base\", token=\"API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined functions\n",
    "To make life a bit easier for you, we have defined a few functions that you can use in this notebook.\n",
    "\n",
    "|function|description|\n",
    "|:---|:---|\n",
    "|`embed`| Embeds a text using the symmetric or asymmetric model|\n",
    "|`cosine_similarity`| Calculates the cosine similarity between two vectors|\n",
    "|`generate_summary`| Generates a summary of a document|\n",
    "|`split_text`| Splits a text into paragraphs|\n",
    "|`evaluate`| Uses the evaluate functionality of luminous to evaluate how good a completion fits to a query|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Sequence\n",
    "from aleph_alpha_client import Prompt, SemanticEmbeddingRequest, SemanticRepresentation, SummarizationRequest, EvaluationRequest, Document\n",
    "\n",
    "# helper function to embed text using the symmetric or asymmetric model\n",
    "def embed(text: str, representation: SemanticRepresentation):\n",
    "    request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=representation)\n",
    "    result = search_model.semantic_embed(request)\n",
    "    return result.embedding\n",
    "\n",
    "# function to calculate similarity\n",
    "def cosine_similarity(v1: Sequence[float], v2: Sequence[float]) -> float:\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "# function for getting a summary\n",
    "def generate_summary(text: str):\n",
    "    request = SummarizationRequest(document=Document.from_text(text))\n",
    "    result = model.summarize(request)\n",
    "    return result.summary\n",
    "\n",
    "# function that splits a text by paragraphs\n",
    "def split_text(text: str):\n",
    "    return text.split(\"\\n\\n\")\n",
    "\n",
    "# function to evaluate two texts\n",
    "def evaluate(text1: str, text2: str):\n",
    "    request = EvaluationRequest(prompt=Prompt.from_text(text1), completion_expected=text2)\n",
    "    result = model.evaluate(request)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Combining Search and Completion\n",
    "\n",
    "This text will probably be too long to put it into a single prompt, so we will have to deal with that.\n",
    "\n",
    "Let's create a function that searches a list of texts based on a question and then generates an answer.\n",
    "- Use search to find the most relevant text\n",
    "- Use a completion request with your own prompt to generate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_to_search = [\n",
    "    \"The judiciary of Poland (Polish: sądownictwo w Polsce) are the authorities exercising the judicial power of the Polish state on the basis of Chapter 8 of the Constitution of Poland.[a] As in almost all countries of continental Europe, the Polish judiciary operates within the framework of civil law.The courts (sądy), designated by the Constitution as those exercising the administration of justice (wymiar sprawiedliwości), are the bodies that review the vast majority of cases, with the exception of those specifically assigned to the two tribunals (trybunały). \",\n",
    "    \"Nicholas Blake 'Nick' Solak (born January 11, 1995) is an American professional baseball second baseman and outfielder for the Texas Rangers of Major League Baseball (MLB). Solak attended Naperville North High School in Naperville, Illinois, and the University of Louisville in Louisville, Kentucky.\",\n",
    "    \"Die Buddhistenkrise war ein Zeitraum politisch-religiöser Anspannungen in Südvietnam vom 8. Mai bis 2. November 1963. Sie wurde durch das Verbot der buddhistischen Flagge durch die Regierung Ngô Đình Diệms ausgelöst, und endete mit einem Putsch der Armee der Republik Vietnam, wobei Ngô Đình Diệm festgenommen und später getötet wurde.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import CompletionRequest\n",
    "\n",
    "text_embeddings = [embed(text, SemanticRepresentation.Document) for text in texts_to_search]\n",
    "\n",
    "def search(query: str):\n",
    "    query_embedding = embed(query, SemanticRepresentation.Query)    \n",
    "    # calculate the similarity between the question and the texts\n",
    "    scores = [cosine_similarity(query_embedding, text_embedding) for text_embedding in text_embeddings]\n",
    "    # select the text with the highest similarity\n",
    "    best_text_index = scores.index(max(scores))\n",
    "    return texts_to_search[best_text_index]\n",
    "\n",
    "def answer(results: str, question: str):\n",
    "    prompt = Prompt(f\"context: {results}\\nquestion:{question}\\nanswer:\")\n",
    "    request = CompletionRequest(prompt=prompt, stop_sequences=[\"\\n\"])\n",
    "    response = model.complete(request)    \n",
    "    return response.completions[0].completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nick Solak (born January 11, 1995) is an American professional baseball second baseman and outfielder for the Texas Rangers of Major League Baseball (MLB). Solak attended Naperville North High School in Naperville, Illinois, and the University of Louisville in Louisville, Kentucky.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who was Nick?\"\n",
    "result = search(query)\n",
    "answer(result, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: \n",
    "Create a function that creates a guided summary of a text.\n",
    "- The function should take a text as input as well as some form of guidance    \n",
    "- There are several ways to solve this task. Try to find a solution that works for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural int...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "text_link = \"https://raw.githubusercontent.com/Aleph-Alpha/examples/main/exercises/text_to_summarize.txt\"\n",
    "req = requests.get(text_link)\n",
    "text_to_summarize = req.text\n",
    "\n",
    "print(text_to_summarize[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that creates a guided summary of a text.\n",
    "# This is a pretty complicated task, so don't worry if you can't get it to work.\n",
    "def guided_summary(text : str, guidance : str):\n",
    "    # Split the text into paragraphs\n",
    "    splits = split_text(text)\n",
    "    embeddings = [embed(split, SemanticRepresentation.Document) for split in splits]\n",
    "    \n",
    "    # Embed the guidance\n",
    "    embedded_guidance = embed(guidance, SemanticRepresentation.Query)\n",
    "    \n",
    "    # calculate a similarity for each of the splits\n",
    "    list_of_scored_splits =  []   # list of tuples (split, score, position)\n",
    "    list_of_scores = []\n",
    "    for i in range(len(splits)):\n",
    "        \n",
    "        # calculate the similarity between the guidance and the split embedding\n",
    "        similarity_score = cosine_similarity(embedded_guidance, embeddings[i])\n",
    "        \n",
    "        # add the similarity score to the list of scored splits\n",
    "        list_of_scored_splits.append((splits[i], similarity_score, i))\n",
    "        \n",
    "        # add the similarity score to the list of scores for accessing the top 3\n",
    "        list_of_scores.append(similarity_score)\n",
    "        \n",
    "    \n",
    "    # select the top 5 splits by score\n",
    "    top_5_splits = sorted(list_of_scored_splits, key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    # sort the top 5 splits by position\n",
    "    top_5_splits = sorted(top_5_splits, key=lambda x: x[2])\n",
    "    \n",
    "    # join the top 5 splits into a guided text\n",
    "    guided_text = \"\\n\".join([x[0] for x in top_5_splits])\n",
    "        \n",
    "    # use the guided text to generate a summary\n",
    "    summary = generate_summary(guided_text)\n",
    "    \n",
    "    return summary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Artificial intelligence is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals and humans.\n",
      "• AI research has developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics. Many of these algorithms proved to be insufficient for solving large reasoning problems because they experienced a \"combinatorial explosion\". Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\n"
     ]
    }
   ],
   "source": [
    "print(guided_summary(text_to_summarize, \"What were breakthrough discoveries?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8bb351cbb231ebe1f2609a46f6d0b60d5d0bc334d8d2f0479e7f916a63419382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
