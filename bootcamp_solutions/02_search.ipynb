{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using a colab notebook:\n",
    "#!git clone https://github.com/Aleph-Alpha/examples.git\n",
    "#!pip install -r examples/requirements.txt\n",
    "#!cp examples/bootcamp/data.md data.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Client, SemanticEmbeddingRequest, CompletionRequest, SemanticEmbeddingResponse, SemanticRepresentation, Prompt, TextControl\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.llms import AlephAlpha\n",
    "from langchain.embeddings import AlephAlphaSymmetricSemanticEmbedding, AlephAlphaAsymmetricSemanticEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = Client(token=os.getenv(\"AA_TOKEN\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Use the API to create an embedding of a text\n",
    "Use the \"Semantic Search\" API to create an embedding of a text. The API returns a JSON object with the embedding of the text.\n",
    "You can read more about the semantic search API here: https://docs.aleph-alpha.com/docs/tasks/semantic_embed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Use the API to find out how similar these three texts are\n",
    "Use scipys cosine_similarity 'spatial.distance.cosine' to find out how similar these three texts are. The function returns a number between 0 and 1, where 0 means the texts are completely different and 1 means the texts are identical.\n",
    "Remember that cosine_similarity returns a distance, not a similarity. So you need to subtract the distance from 1 to get the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"The sun is shining\", \n",
    "         \"It's pretty sunny today\", \n",
    "         \"Her smile shines brightly down upon the south african people\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create an embedding request (Symmetric), get the response, and extract the embedding\n",
    "text_embeddings = []\n",
    "for text in texts:\n",
    "    embedding_request = SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Symmetric, compress_to_size=128)\n",
    "    embedding_response = client.semantic_embed(embedding_request, model=\"luminous-base\")\n",
    "    embedding = embedding_response.embedding\n",
    "    text_embeddings.append(embedding)\n",
    "\n",
    "# TODO: Calculate the cosine similarity between the embeddings\n",
    "similarity_1_2 = 1 - spatial.distance.cosine(text_embeddings[0], text_embeddings[1])\n",
    "similarity_1_3 = 1 - spatial.distance.cosine(text_embeddings[0], text_embeddings[2])\n",
    "similarity_2_3 = 1 - spatial.distance.cosine(text_embeddings[1], text_embeddings[2])\n",
    "\n",
    "print(f\"Similarity between {texts[0][:10]} and {texts[1][:10]}\", similarity_1_2)\n",
    "print(f\"Similarity between text {texts[0][:10]} and {texts[2][:10]}: \", similarity_1_3)\n",
    "print(f\"Similarity between text {texts[1][:10]} and {texts[2][:10]}: \", similarity_2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic similarity with langchain    \n",
    "embeddings = AlephAlphaSymmetricSemanticEmbedding()\n",
    "\n",
    "text_embeddings = embeddings.embed_documents(texts)\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i+1, len(texts)):\n",
    "        similarity = 1 - spatial.distance.cosine(text_embeddings[i], text_embeddings[j])\n",
    "        print(f\"Similarity between {texts[i][:10]} and {texts[j][:10]}\", similarity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Use the API on an asymmetric embedding case to find the answer to the question\n",
    "Asymmetric embeddings are useful when you want to find the answer to a question. For example, if you want to find the answer to the question \"What is the capital of France?\", you can use the API to create an embedding of the question and an embedding of the answer. Then you can use the cosine_similarity function to find out how similar the question and the answer are. The answer is the one with the highest similarity.\n",
    "\n",
    "We will try this on parts of the manual.\n",
    "\n",
    "You can find the documentation on the asymmetric embedding here: https://docs.aleph-alpha.com/docs/tasks/semantic_embed/#code-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data in the data.md file\n",
    "with open(\"data.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# Split the data into a list of texts\n",
    "texts = data.split(\"#\")\n",
    "\n",
    "# remove the first element of the list\n",
    "texts = texts[1:]\n",
    "\n",
    "print(f\"data: {data[:100]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the text files\n",
    "question = \"What are macr trends?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create embeddings (Document) for the contexts and the question (Query)\n",
    "embedded_contexts = []\n",
    "for context in texts:\n",
    "    # TODO: create an embedding request (Document), \n",
    "    # get the response, \n",
    "    # and extract the embedding\n",
    "    embedding_request = SemanticEmbeddingRequest(\n",
    "        prompt=Prompt.from_text(context), \n",
    "        representation=SemanticRepresentation.Document, \n",
    "        compress_to_size=128)\n",
    "    embedding_response = client.semantic_embed(embedding_request, model=\"luminous-base\")\n",
    "    embedding = embedding_response.embedding\n",
    "    embedded_contexts.append(embedding)\n",
    "\n",
    "# TODO\n",
    "# create an embedding request (Query), \n",
    "# get the response, \n",
    "# and extract the embedding\n",
    "embedded_question = client.semantic_embed(\n",
    "    SemanticEmbeddingRequest(\n",
    "        prompt=Prompt.from_text(question), \n",
    "        representation=SemanticRepresentation.Query, \n",
    "        compress_to_size=128), \n",
    "    model=\"luminous-base\").embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create embeddings (Document) for the contexts and the question (Query) with langchain\n",
    "\n",
    "# Load the embedding model\n",
    "embeddings = AlephAlphaAsymmetricSemanticEmbedding()\n",
    "\n",
    "# TODO: create embeddings (Document) for the contexts and the question (Query)\n",
    "embedded_contexts = embeddings.embed_documents(texts)\n",
    "embedded_question = embeddings.embed_query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the cosine similarity between the embeddings\n",
    "similarities = []\n",
    "for embedded_context in embedded_contexts:\n",
    "    # TODO: Calculate the cosine similarity between the embeddings\n",
    "    similarity = 1 - spatial.distance.cosine(embedded_context, embedded_question)\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "print(\"Similarities: \", similarities)\n",
    "print(\"\\n\\nSelected Context: \\n\" + texts[np.argmax(similarities)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we spin up the Qdrant server\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "\n",
    "q_client = QdrantClient(path=\"db\")\n",
    "\n",
    "q_client.recreate_collection(\n",
    "    collection_name=\"test_collection\",\n",
    "    vectors_config=VectorParams(size=128, distance=Distance.COSINE),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create embeddings for each of the texts and store them in a list\n",
    "embeddings = []\n",
    "for text in texts:\n",
    "    # TODO: embed the texts\n",
    "    embeddings.append(client.semantic_embed(SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Document, compress_to_size=128), model=\"luminous-base\").embedding)\n",
    "    \n",
    "    \n",
    "# now we can upsert the data into Qdrant\n",
    "ids = list(range(len(texts)))\n",
    "payloads = [{\"text\": text} for text in texts]\n",
    "\n",
    "q_client.upsert(\n",
    "     collection_name=\"test_collection\",\n",
    "     points=Batch(\n",
    "     ids=ids,\n",
    "     payloads=payloads,\n",
    "     vectors=embeddings\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO write a function that takes a question and returns an answer by searching in the Qdrant database\n",
    "def search_and_answer(question):\n",
    "    # TODO First we embed the question\n",
    "    embedded_question = client.semantic_embed(SemanticEmbeddingRequest(prompt=Prompt.from_text(question), representation=SemanticRepresentation.Query, compress_to_size=128), model=\"luminous-base\").embedding\n",
    "    \n",
    "    # Then we search for the most similar text\n",
    "    search_result = q_client.search(\n",
    "        collection_name=\"test_collection\",\n",
    "        query_vector=embedded_question,\n",
    "        filter=None,\n",
    "        top=1,\n",
    "    )\n",
    "    \n",
    "    print(search_result)\n",
    "        \n",
    "    # return \"no answer found\" if no result has a score above 0.3\n",
    "    if search_result[0].score < 0.3:\n",
    "        return \"no answer found\"\n",
    "    \n",
    "    \n",
    "    # Then we get the text from the search result\n",
    "    text = search_result[0].payload[\"text\"]\n",
    "    \n",
    "    # TODO Finally we ask luminous to answer the question based on the text\n",
    "    prompt = f\"\"\"### Instructions: Answer the question briefly based on the provided Input.\n",
    "    \n",
    "    ### Input: {text}\n",
    "    \n",
    "    ### Question: {question}\n",
    "    \n",
    "    ### Response:\"\"\"\n",
    "    \n",
    "    # TODO write the CompletionRequest\n",
    "    request = CompletionRequest(prompt=Prompt.from_text(prompt), maximum_tokens=64, stop_sequences=[\"###\"])\n",
    "    \n",
    "    # TODO get the response from luminous\n",
    "    response = client.complete(request, model=\"luminous-extended-control\")\n",
    "    \n",
    "    return response.completions[0].completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_and_answer(\"When was the cooperation agreement signed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpe-hmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fb2148b4dec95289a29917982720107fca12734259108fc6abb6a274b2eb7e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
