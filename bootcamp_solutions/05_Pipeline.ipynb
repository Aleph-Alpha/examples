{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Client, Prompt, CompletionRequest, CompletionResponse, SemanticEmbeddingRequest, SemanticEmbeddingResponse, SemanticRepresentation\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = Client(token=os.getenv(\"AA_TOKEN\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Let's do a really simple QA prompt\n",
    "In this step we will ask luminous a question from the manual. Let's see how it answers.\n",
    "Write a completionrequest and make luminous answer it. Don't forget the stop sequences.\n",
    "You can find the documentation for the completionrequest here: https://docs.aleph-alpha.com/docs/tasks/complete/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, the world is not flat.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Q: Is the world flat?\\nA:\"\n",
    "\n",
    "# TODO: Write the completion request\n",
    "request = CompletionRequest(prompt=Prompt.from_text(prompt), maximum_tokens=32, stop_sequences=[\"\\n\"])\n",
    "\n",
    "# TODO: Call the client to run the completionrequest\n",
    "response = client.complete(request, model=\"luminous-extended\")\n",
    "print(response.completions[0].completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Let's do a QA prompt with a context\n",
    "Obviously, we can't expect luminous to answer the question if we don't give it any context. Let's see how it answers when we give it some context.\n",
    "Write the new prompt and make luminous answer it. Don't forget the stop sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stop Category 0 is defined as stopping by immediate removal of power to the machine actuators.\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"The robot has protective and emergency stop functions (stop category 0 or 1, in accordance with IEC 60204-1).\n",
    "\n",
    "| Stop category 0 | As defined in IEC 60204-1, stopping by immediate removal of power to the machine actuators. |  \n",
    "|---|---|  \n",
    "| Stop category 1 | As defined in IEC 60204-1, a controlled stop with power avail- able to the machine actuators to achieve the stop and then re- moval of power when the stop is achieved. |  \"\"\"\n",
    "\n",
    "# TODO write a prompt that makes luminous answer the question based on the context\n",
    "prompt = f\"\"\"### Instructions: Answer the question based on the provided Context. If the answer is not in the text return \"not answerable\".\n",
    "### Input: {context}\n",
    "### Question: How is Stop Category 0 defined?\n",
    "Short Answer:\"\"\"\n",
    "\n",
    "request = CompletionRequest(prompt=Prompt.from_text(prompt), maximum_tokens=32, stop_sequences=[\"###\"])\n",
    "\n",
    "response = client.complete(request, model=\"luminous-base-control-beta\")\n",
    "print(response.completions[0].completion)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Let's use our search we coded in the previous notebook to find the relevant context for the question and then use that context to answer the question\n",
    "This step is a bit long, but it is a good exercise to see how we can use the search we coded in the previous notebook to find the relevant context for the question and then use that context to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pinocchio was made by a carpenter named Geppetto.\n",
      "Pinocchio was not a boy, but a wooden puppet. He was made by a carpenter named Geppetto. He was a very naughty puppet. He was always getting into trouble. He was always lying.\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Pinocchio was not a boy, but a wooden puppet. He was made by a carpenter named Geppetto. He was a very naughty puppet. He was always getting into trouble. He was always lying.\",\n",
    "    \"Most commonly associated with the polar regions, permafrost is soil and rocky material that stays frozen continuously for at least two years. Normally it lies beneath an active layer that melts and freezes depending on the season. Less well known is that permafrost can also be found on steep mountain walls.\",\n",
    "    \"Toheroa are a clam that grow as large as a human hand and burrow in intertidal sands on just a handful of epic surf-swept beaches found mainly on the west coast of New Zealand's North Island, but also in isolated colonies at places like Oreti, a beach at the nation's southern tip.\",\n",
    "    \"On the neighbourhood's southern edge, cutting through Queens like a backbone, is Roosevelt Avenue. Here, conversations don't stop when the 7 train rattles overhead, they just get louder. Phone repair shops run by Tibetans with makeshift shrines displayed between plastic iPhone covers abut Latin American bakeries churning out pillowy almoj√°banas (Colombian cheese bread) and crispy empanadas.\"\n",
    "]\n",
    "        \n",
    "question = \"Who made Pinocchio?\"\n",
    "\n",
    "#TODO: embed the contexts\n",
    "\n",
    "embedded_texts = []\n",
    "for text in texts:\n",
    "    embedded_texts.append(client.semantic_embed(SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Document, compress_to_size=128), model=\"luminous-base\").embedding)\n",
    "\n",
    "# TODO: embed the question\n",
    "embedded_question = client.semantic_embed(SemanticEmbeddingRequest(prompt=Prompt.from_text(question), representation=SemanticRepresentation.Query, compress_to_size=128), model=\"luminous-base\").embedding\n",
    "\n",
    "# TODO: calculate the cosine similarity between the question and the contexts\n",
    "similarities = []\n",
    "for embedded_text in embedded_texts:\n",
    "    similarities.append(1 - spatial.distance.cosine(embedded_text, embedded_question))\n",
    "\n",
    "# Get the text in the most similar context\n",
    "selected_context = texts[np.argmax(similarities)]\n",
    "\n",
    "# TODO: write a prompt that makes luminous answer the question based on the context\n",
    "prompt = f\"\"\"### Instructions: Answer the question briefly based on the provided Input. If the answer is not in the text return \"not answerable\".\n",
    "### Input: {selected_context}\n",
    "### Question: {question}\n",
    "### Response:\"\"\"\n",
    "\n",
    "# TODO: write the CompletionRequest\n",
    "request = CompletionRequest(prompt=Prompt.from_text(prompt), maximum_tokens=64, stop_sequences=[\"###\"])\n",
    "\n",
    "response = client.complete(request, model=\"luminous-base-control-beta\")\n",
    "\n",
    "print(response.completions[0].completion)\n",
    "print(selected_context)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try this with a more complex setup and a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we spin up the Qdrant server\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "\n",
    "q_client = QdrantClient(path=\"db\")\n",
    "\n",
    "q_client.recreate_collection(\n",
    "    collection_name=\"test_collection\",\n",
    "    vectors_config=VectorParams(size=128, distance=Distance.COSINE),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we load our data from data.md\n",
    "\n",
    "with open(\"data.md\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# Lets split the data by headings (###)\n",
    "data = data.split(\"###\")\n",
    "\n",
    "# remove the first element as it is empty\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Highlights\\n\\n- Provides high performance and scalability\\n\\n- Develops and deploys new optimization-based models\\n\\n- Makes a difference with real- world applications\\n\\n- Available for testing via the free Community Edition\\n\\n- Enables flexible deployment of optimization models on premises and on cloud\\n\\n',\n",
       " ' Overview\\n\\nDecision optimization is a mathematical technique used to help  \\nmake complex business decisions that have the potential for business disruption and involve many large data sources, multiple trade-  \\noff possibilities and complex constraints. This advanced analytics technique is often used for planning, scheduling and pricing, as well as other business applications. Organizations across the world have seen business value and high ROI from optimization, as demonstrated through successful projects in a wide range of industries.\\n\\nIBM Decision Optimization products enable business decision-  \\nmaking processes such as operational, tactical and strategic planning and scheduling. They can be used in a range of industries, including manufacturing, energy and utilities, finance and logistics. The  \\nDecision Optimization portfolio includes modeling tools, solvers  \\nand deployment capabilities to make decision optimization capabilities available for planning, scheduling and resource allocation scenarios.  \\nIt supports operations research experts with modeling activities in the mathematical, constraint programming and constraint-based scheduling model domain, and also facilitates collaboration between operations research experts and IT developers in their deployment needs. Business users can benefit from a tailored graphical user interface and access other advanced features like predictive analytics and machine learning, or business functions like control and execution systems, without having to worry about the underlying optimization technology.\\n\\n---\\n\\n',\n",
       " ' IBM ILOG CPLEX Optimization Studio\\n\\nIBM ¬Æ ILOG ¬Æ CPLEX ¬Æ Optimization Studio provides powerful modeling tools to convert a business problem to a mathematical model and then solve it. Solving a mathematical model would provide an optimal solution for achieving a business goal, replacing intuition and heuristic thinking with\\n\\n**Inputs** Minimize costs  \\nDemand to be met  \\n**Mathematical**  \\n**models**  \\nResources available  \\n**Using one or many** SpeciÔ¨Åc **Schedule** Maximize resource **or plan** yields Costs, yields, and recipes\\n\\n',\n",
       " ' Optimization engines\\n\\nassignments **with metrics** fact-based, measurable decisions. With exact mathematical Operation constraints and  \\ncustomer preferences\\n\\nBest possible algorithms, proving optimality (that no better solution,  \\ndecision or action exists) is also possible. This enables the  \\nuser to understand what is possible and how much it would  \\ncost to do it, thereby providing great business advantage over  \\ncompetitors who base their decisions on heuristics or rules.\\n\\nThis analytical decision support toolkit supports rapid model development and solving by combining the Integrated Development Environment (IDE), the Optimization Programming Language (OPL) for modelling, and two solvers: IBM ILOG CPLEX Optimizer for mathematical programming models, and IBM ILOG CPLEX CP Optimizer for constraint programming and constraint-based scheduling models.\\n\\nThe core technologies of IBM ILOG CPLEX Optimization Studio provide:\\n\\n- Solutions for all sizes of optimization models, with no limit on the number of constraints and variables (although the size of the hardware limits the size of the model).\\n- Solutions in real time to support operational process requirements by providing unmatched performance of best-in-class algorithms.\\n- Multiple solver algorithms for different type of models to help choose the best algorithm for any specific situation. The mathematical programming solver provides LP, MIP and MIQCP algorithms, while the constraint solver provides solutions for models involving any type of constraints (including non-linear) over integer variables, as well as scheduling models over cumul functions (AKA resources) and interval variables (AKA activities).\\n- Optimal solutions and consistently short solution times across numerous problem instances. If the user wants  \\nto end the solve before optimality is proven, bounds and gaps are given, showing how close the potential optimum solution is (both for math and constraint programming).\\n- Ability to design interactive optimization models to adapt to real-world situations where data and business conditions change frequently.\\n\\nBusiness Goals  \\ntiming of activities\\n\\n*Figure 1.* The core technologies of IBM ILOG CPLEX Optimization Studio.\\n\\n',\n",
       " ' IBM ILOG CPLEX Optimization Studio Community Edition\\n\\nThere is no better way to test the power of IBM ILOG CPLEX Optimization Studio than through a hands-on approach of solving pertinent optimization problems. While traditional software trials give users the ability to test the software, they generally have a strict time limit. In recognition of that, IBM now offers a free Community Edition, which gives users the freedom to fully test the software and run models with up to 1,000 variables and 1,000 constraints.\\n\\nIn the IBM Marketplace, users can download the free Community Edition by visiting ibm.biz/BdZ7Wx. IBM  \\nalso provides a subscription option where users can buy the full version of IBM ILOG CPLEX Optimization Studio development edition on a month-to-month basis in a self- served manner.\\n\\n',\n",
       " ' Enabling flexible solves\\n\\nThe IBM ILOG CPLEX Optimization Studio IDE provides an ideal environment to develop OPL models. In addition, it now allows users to seamlessly connect to IBM cloud resources through IBM Decision Optimization on Cloud, which fuses the power of the on-premises Decision Optimization offering with the scalability of deployment on the IBM Cloud TM infrastructure.\\n\\nThis flexibility gives users of the on-premises IDE the ability to solve their optimization problems with any of the two solvers on the cloud from their desktop. Though modeling in OPL is the best way to convert business problems to optimization models, users who want to directly model in APIs can use C, C++, Java, C\\\\# or Python APIs as well.\\n\\n---\\n\\n',\n",
       " ' Providing high performance Making a difference with real-world\\n\\nand scalability applications The solver engines solve a wide range of optimization models  \\nwhile also delivering superior performance. In addition,  \\nusers get total flexibility for modeling with a compact and  \\nexpressive OPL, and an IDE with diverse model  \\ndevelopment services.\\n\\nDeveloping and deploying new\\n\\n',\n",
       " ' optimization models\\n\\nUsers can realize significant competitive gains through the ability to rapidly implement and integrate new optimization models to support emerging business needs.\\n\\nIBM ILOG CPLEX Optimization Studio supports comprehensive model development and deployment through its intuitive modeling language (OPL), IDE, development services such as debugging, profiling, tuning, conflict detection and refinement, and solvers for mathematical programming and constraint programming and scheduling.\\n\\nEnterprises can take advantage of the optimization models that IBM ILOG CPLEX Optimization Studio helps create in the following ways:\\n\\n- The optimization models can be deployed through embedding APIs. (OPL has API embedding, and the API modeling contains embedding parts.)\\n- The models can be deployed through CPLEX Enterprise Server, based on IBM WebSphere ¬Æ Application Server.\\n- The models can be deployed in an application created using IBM Decision Optimization Center (client  \\nor server).\\n- The models can be deployed on the IBM cloud (IBM Decision Optimization for Cloud) through a REST API.\\n- IBM SPSS ¬Æ Modeler delivers the OPL node, as well as the Python model extension (optimization models written in Python API) so all SPSS Modeler deployment facilities can be used for optimization model deployment.\\n\\nOrganizations in a range of industries use IBM ILOG CPLEX Optimization Studio to achieve better outcomes:\\n\\n- A major transportation company reduced operating costs by USD 26 million annually through better allocation of rolling stock.\\n- A central securities depository saved USD 240 million for financial institutions in 18 months by clearing securities transactions faster.\\n- A power system operator reduced daily costs to consumers by USD 66,000 through better dispatch of generators.\\n- A major hotel chain increased annual revenue by USD 226 million by offering the right product to the right customer at the right price.\\n\\nWhy IBM Decision Optimization?  \\nIBM Decision Optimization brings more than 25 years  \\nof experience in the field and is a proven optimization technology. In the domain of decision optimization, the prestigious Edelman Prize is given each year to the best practitioner project in operations research. Over the past decade, four times as many Edelman finalists have used  \\nIBM ILOG CPLEX Optimizer than any other optimization technology to build innovative solutions to difficult challenges.\\n\\nIn addition, IBM has one of the largest groups of OR, IT cloud and industry solutions experts from product teams, IBM Research, and IBM Global Business Services. This combined expertise helps to ensure leading-edge product development and support for customer needs. From integrating with the IBM SPSS Modeler predictive analytics engine to running optimization algorithms on cloud to allowing for user collaboration and powerful visualizations in an intuitive user interface, IBM Decision Optimization solutions provide  \\na comprehensive end-to-end solution for even the most complex challenges.\\n\\n---\\n\\n',\n",
       " ' For more information\\n\\nTo learn more about IBM ILOG CPLEX Optimization Studio, please contact your IBM representative or IBM Business Partner, or visit ibm.co/2j5RvHi.\\n\\nTo register for the IBM ILOG CPLEX Optimization Studio free trial, visit ibm.biz/BdZ7Wx.\\n\\nIBM Global Financing can help you acquire the IT solutions that your business needs in the most cost-effective and strategic way possible. We‚Äôll partner with credit-qualified clients to customize an IT financing solution to suit your business goals, enable effective cash management, and improve your total cost of ownership. IBM Global Financing is your smartest choice to fund critical IT investments and propel your business forward. For more information, visit ibm.com/financing.\\n\\n¬© Copyright IBM Corporation 2018\\n\\nIBM Corporation  \\n1 New Orchard Road Armonk, NY 10504\\n\\nProduced in the United States of America June 2018\\n\\nIBM, the IBM logo, ibm.com, CPLEX, WebSphere and SPSS are trademarks of International Business Machines Corp., registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the Web at ‚ÄúCopyright and trademark information‚Äù at ibm.com/legal/copytrade.shtml\\n\\nThis document is current as of the initial date of publication and may be changed by IBM at any time. Not all offerings are available in every country in which IBM operates.\\n\\nThe performance data and client examples cited are presented for illustrative purposes only. Actual performance results may vary depending on specific configurations and operating conditions. Actual results  \\nmay vary.\\n\\nTHE INFORMATION IN THIS DOCUMENT IS PROVIDED  \\n‚ÄúAS IS‚Äù WITHOUT ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING WITHOUT ANY WARRANTIES OF MERCHANT- ABILITY, FITNESS FOR A PARTICULAR PURPOSE AND ANY WARRANTY OR CONDITION OF NON-INFRINGEMENT. IBM products are warranted according to the terms and conditions of the agreements under which they are provided.\\n\\nPlease Recycle\\n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create embeddings for each of the texts and store them in a list\n",
    "embeddings = []\n",
    "for text in data:\n",
    "    # TODO: embed the texts\n",
    "    embeddings.append(client.semantic_embed(SemanticEmbeddingRequest(prompt=Prompt.from_text(text), representation=SemanticRepresentation.Document, compress_to_size=128), model=\"luminous-base\").embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can upsert the data into Qdrant\n",
    "ids = list(range(len(data)))\n",
    "payloads = [{\"text\": text} for text in data]\n",
    "\n",
    "q_client.upsert(\n",
    "     collection_name=\"test_collection\",\n",
    "     points=Batch(\n",
    "     ids=ids,\n",
    "     payloads=payloads,\n",
    "     vectors=embeddings\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO write a function that takes a question and returns an answer by searching in the Qdrant database\n",
    "def search_and_answer(question):\n",
    "    # TODO First we embed the question\n",
    "    embedded_question = client.semantic_embed(SemanticEmbeddingRequest(prompt=Prompt.from_text(question), representation=SemanticRepresentation.Query, compress_to_size=128), model=\"luminous-base\").embedding\n",
    "    \n",
    "    # Then we search for the most similar text\n",
    "    search_result = q_client.search(\n",
    "        collection_name=\"test_collection\",\n",
    "        query_vector=embedded_question,\n",
    "        filter=None,\n",
    "        top=1\n",
    "    )\n",
    "    \n",
    "    # Then we get the text from the search result\n",
    "    text = search_result[0].payload[\"text\"]\n",
    "    \n",
    "    # TODO Finally we ask luminous to answer the question based on the text\n",
    "    prompt = f\"\"\"### Instructions: Answer the question briefly based on the provided Input. If the answer is not in the text return \"not answerable\".\n",
    "    \n",
    "    ### Input: {text}\n",
    "    \n",
    "    ### Question: {question}\n",
    "    \n",
    "    ### Response:\"\"\"\n",
    "    \n",
    "    # TODO write the CompletionRequest\n",
    "    request = CompletionRequest(prompt=Prompt.from_text(prompt), maximum_tokens=64, stop_sequences=[\"###\"])\n",
    "    \n",
    "    # TODO get the response from luminous\n",
    "    response = client.complete(request, model=\"luminous-base-control-beta\")\n",
    "    \n",
    "    return response.completions[0].completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' not answerable'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_and_answer(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The community edition of IBM ILOG CPLEX Optimization Studio allows users to fully test the software and run models with up to 1,000 variables and 1,000 constraints.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_and_answer(\"What can I do with the community edition?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpe-hmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fb2148b4dec95289a29917982720107fca12734259108fc6abb6a274b2eb7e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
