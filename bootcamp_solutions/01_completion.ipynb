{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Client, Prompt, CompletionRequest, CompletionResponse\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.llms import AlephAlpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# for using the Aleph Alpha API\n",
    "client = Client(token=os.getenv(\"AA_TOKEN\"))\n",
    "\n",
    "# for using LangChain\n",
    "aleph_alpha = AlephAlpha(aleph_alpha_api_key=os.getenv(\"AA_TOKEN\"), model=\"luminous-extended\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Use the completion function of the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " keeps the doctor away, but if you have a heart condition, it could also save your life.\n"
     ]
    }
   ],
   "source": [
    "# using the full-fledged AA API for a simple completion\n",
    "\n",
    "# Define the prompt\n",
    "prompt = Prompt.from_text(\"An apple a day\")\n",
    "\n",
    "# Create a completion request with parameters\n",
    "request = CompletionRequest(prompt=prompt, \n",
    "                            maximum_tokens=100, \n",
    "                            temperature=0.5, \n",
    "                            stop_sequences=[\"\\n\"])\n",
    "\n",
    "# Send the request to the API\n",
    "response = client.complete(request=request, model=\"luminous-extended\")\n",
    "\n",
    "# Get the completion\n",
    "completion = response.completions[0].completion\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " keeps the doctor away, but there are other options for those who don’t like apples, or have other dietary restrictions.\n"
     ]
    }
   ],
   "source": [
    "# using LangChain for a simple completion\n",
    "\n",
    "# define the prompt\n",
    "prompt = \"An apple a day\"\n",
    "\n",
    "# define the parameters\n",
    "params = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"model\": \"luminous-extended\",\n",
    "    \"maximum_tokens\": 100\n",
    "}\n",
    "\n",
    "# define the model\n",
    "aleph_alpha = AlephAlpha(aleph_alpha_api_key=os.getenv(\"AA_TOKEN\"), **params)\n",
    "\n",
    "# get the completion\n",
    "response = aleph_alpha(prompt=prompt, stop=[\"\\n\"])\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Write a few shot prompt that generates keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pinocchio\n",
      " Pinocchio\n",
      "permafrost\n",
      "permafrost\n",
      "Toheroa\n",
      "Toheroa\n",
      " Roosevelt Avenue\n",
      " Roosevelt Avenue\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Pinocchio was not a boy, but a wooden puppet. He was made by a carpenter named Geppetto. He was a very naughty puppet. He was always getting into trouble. He was always lying.\",\n",
    "    \"Most commonly associated with the polar regions, permafrost is soil and rocky material that stays frozen continuously for at least two years. Normally it lies beneath an active layer that melts and freezes depending on the season. Less well known is that permafrost can also be found on steep mountain walls.\",\n",
    "    \"Toheroa are a clam that grow as large as a human hand and burrow in intertidal sands on just a handful of epic surf-swept beaches – mainly on the west coast of New Zealand's North Island, but also in isolated colonies at places like Oreti, a beach at the nation's southern tip.\",\n",
    "    \"On the neighbourhood's southern edge, cutting through Queens like a backbone, is Roosevelt Avenue. Here, conversations don't stop when the 7 train rattles overhead, they just get louder. Phone repair shops run by Tibetans with makeshift shrines displayed between plastic iPhone covers abut Latin American bakeries churning out pillowy almojábanas (Colombian cheese bread) and crispy empanadas.\"\n",
    "]\n",
    "\n",
    "# TODO write a function that takes a text and returns a list of keywords\n",
    "\n",
    "def get_keywords(text):\n",
    "    # TODO Write a prompt that generates keywords for any text\n",
    "    # Tipp: Use few-shot learning\n",
    "    \n",
    "    # 1. define the prompt\n",
    "    prompt = Prompt.from_text(f\"\"\"Task: Extract topic from the text.\\nText:{text}\\ntopic:\"\"\")   \n",
    "    \n",
    "    # 2. define the completion request \n",
    "    request = CompletionRequest(prompt=prompt, \n",
    "                                    maximum_tokens=32, \n",
    "                                    temperature=0, \n",
    "                                    stop_sequences=[\"\\n\"])\n",
    "    \n",
    "    # 3. send the request to the API\n",
    "    response = client.complete(request=request, model=\"luminous-base\")\n",
    "    \n",
    "    # 4. get the completion\n",
    "    completion = response.completions[0].completion\n",
    "    return completion\n",
    "\n",
    "def get_keywords_langchain(text):\n",
    "    # TODO Write a prompt that generates keywords for any text\n",
    "    # Tipp: Use few-shot learning\n",
    "    \n",
    "    # 1. define the prompt\n",
    "    prompt = f\"\"\"Task: Extract topic from the text.\\nText:{text}\\ntopic:\"\"\"\n",
    "    \n",
    "    # 2. define the parameters\n",
    "    params = {\n",
    "        \"temperature\": 0.5,\n",
    "        \"model\": \"luminous-base\",\n",
    "        \"maximum_tokens\": 100\n",
    "    }\n",
    "\n",
    "    # 3. define the model\n",
    "    aleph_alpha = AlephAlpha(aleph_alpha_api_key=os.getenv(\"AA_TOKEN\"), **params)\n",
    "    \n",
    "    # 4. get the completion\n",
    "    response = aleph_alpha(prompt=prompt, stop=[\"\\n\"])\n",
    "    return response\n",
    "    \n",
    "\n",
    "for text in texts:\n",
    "    keywords = get_keywords(text)\n",
    "    print(keywords)\n",
    "    keywords_lang = get_keywords_langchain(text)\n",
    "    print(keywords_lang)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use Langchain to run a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems.\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a chain from langchain to generate a text\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Q: {question}\n",
    "\n",
    "A:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm = AlephAlpha(model=\"luminous-extended\", maximum_tokens=20, stop_sequences=[\"Q:\"], aleph_alpha_api_key=os.getenv(\"AA_TOKEN\"))\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What is AI?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
